{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654},{"sourceId":9532663,"sourceType":"datasetVersion","datasetId":5805639},{"sourceId":9532701,"sourceType":"datasetVersion","datasetId":5805666}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport numpy as np \nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.318002Z","iopub.execute_input":"2024-10-02T15:56:37.318948Z","iopub.status.idle":"2024-10-02T15:56:37.325834Z","shell.execute_reply.started":"2024-10-02T15:56:37.318898Z","shell.execute_reply":"2024-10-02T15:56:37.324907Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# def initialize_weight_goog(m):\n#     if isinstance(m, nn.Linear):\n#         fan_out = m.weight.size(0)\n#         fan_in = 0\n#         init_range = 1.0 / math.sqrt(fan_in + fan_out)\n#         m.weight.data.uniform_(-init_range, init_range)\n#         m.bias.data.zero_(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.327678Z","iopub.execute_input":"2024-10-02T15:56:37.328654Z","iopub.status.idle":"2024-10-02T15:56:37.337359Z","shell.execute_reply.started":"2024-10-02T15:56:37.328621Z","shell.execute_reply":"2024-10-02T15:56:37.336431Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.338975Z","iopub.execute_input":"2024-10-02T15:56:37.339254Z","iopub.status.idle":"2024-10-02T15:56:37.346159Z","shell.execute_reply.started":"2024-10-02T15:56:37.339224Z","shell.execute_reply":"2024-10-02T15:56:37.345240Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.347408Z","iopub.execute_input":"2024-10-02T15:56:37.348011Z","iopub.status.idle":"2024-10-02T15:56:37.355250Z","shell.execute_reply.started":"2024-10-02T15:56:37.347970Z","shell.execute_reply":"2024-10-02T15:56:37.354403Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.357483Z","iopub.execute_input":"2024-10-02T15:56:37.357834Z","iopub.status.idle":"2024-10-02T15:56:37.366494Z","shell.execute_reply.started":"2024-10-02T15:56:37.357790Z","shell.execute_reply":"2024-10-02T15:56:37.365267Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.ca = ChannelAttention(planes)\n        self.sa = SpatialAttention()\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out = self.ca(out) * out\n        out = self.sa(out) * out\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.367800Z","iopub.execute_input":"2024-10-02T15:56:37.368403Z","iopub.status.idle":"2024-10-02T15:56:37.380545Z","shell.execute_reply.started":"2024-10-02T15:56:37.368367Z","shell.execute_reply":"2024-10-02T15:56:37.379257Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class ResNetWithSCN(nn.Module):\n\n    def __init__(self, block, layers, num_heads, num_classes=7):\n        self.inplanes = 64\n        # self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        super(ResNetWithSCN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n        self.attention = nn.MultiheadAttention(128, num_heads)\n        self.layer_norm = nn.LayerNorm(128)\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.linear1 = nn.Linear(128,64)\n        self.relu1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(0.5)   \n        self.classifier = nn.Linear(64, num_classes)\n            # nn.Linear(256,128),\n            # nn.ReLU(),\n            # nn.Dropout(0.5),\n            # nn.Linear(128, num_classes)\n        \n        self.alpha = nn.Sequential(\n            # nn.Linear(256,128),\n            # nn.ReLU(),\n            # nn.Dropout(0.5),\n            # nn.Linear(128, num_classes)\n            nn.Linear(64,1),\n            nn.Sigmoid()\n        )\n\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                fan_out = m.weight.size(0)  # fan-out\n                fan_in = m.weight.size(1) if m.weight.dim() > 1 else 0  # fan-in\n                init_range = 1.0 / math.sqrt(fan_in + fan_out)\n                m.weight.data.uniform_(-init_range, init_range)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n        for m in self.alpha.modules():\n            if isinstance(m, nn.Linear):\n                fan_out = m.weight.size(0)  # fan-out\n                fan_in = m.weight.size(1) if m.weight.dim() > 1 else 0  # fan-in\n                init_range = 1.0 / math.sqrt(fan_in + fan_out)\n                m.weight.data.uniform_(-init_range, init_range)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n#         x = self.layer3(x)\n        # x = self.layer4(x)\n\n        # x = self.avgpool(x)\n        # x = x.view(x.size(0), -1)\n        # x = self.fc(x)\n        batch_size, channels, height, width = x.shape\n        x = x.view(batch_size, channels, height*width).permute(0,2,1)\n\n        query = x\n        key = x\n        value = x\n\n        attn_output, _ = self.attention(query, key, value)\n        x = self.layer_norm(attn_output + x)\n        x = x.permute(0,2,1).view(batch_size, channels, height, width)\n        # x = nn.functional.adaptive_avg_pool2d(x,1).view(batch_size, -1)\n        x = self.global_avg_pool(x).view(batch_size, -1)\n        x = self.linear1(x)\n        x = self.relu1(x)\n        x = self.dropout1(x)\n        \n        attention_weights = self.alpha(x)\n        out = attention_weights * self.classifier(x)\n\n        return attention_weights, out","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.478543Z","iopub.execute_input":"2024-10-02T15:56:37.478842Z","iopub.status.idle":"2024-10-02T15:56:37.500670Z","shell.execute_reply.started":"2024-10-02T15:56:37.478812Z","shell.execute_reply":"2024-10-02T15:56:37.499624Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def resnet18_cbam_with_SCN(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    num_heads = 1\n    model = ResNetWithSCN(BasicBlock, [2, 2, 2, 2], num_heads)\n    # if pretrained:\n    #     pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n    #     now_state_dict        = model.state_dict()\n    #     now_state_dict.update(pretrained_state_dict)\n    #     model.load_state_dict(now_state_dict, strict=False)\n    \n    # New Code Starts From Here\n    if pretrained:\n        checkpoint = torch.load(r\"/kaggle/working/models/1head_SCN_epoch_20_acc_0.7832.pth\")\n        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n    # Ends Here\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:20:39.084250Z","iopub.execute_input":"2024-10-02T16:20:39.084642Z","iopub.status.idle":"2024-10-02T16:20:39.090884Z","shell.execute_reply.started":"2024-10-02T16:20:39.084605Z","shell.execute_reply":"2024-10-02T16:20:39.089768Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.512724Z","iopub.execute_input":"2024-10-02T15:56:37.513052Z","iopub.status.idle":"2024-10-02T15:56:37.525245Z","shell.execute_reply.started":"2024-10-02T15:56:37.513020Z","shell.execute_reply":"2024-10-02T15:56:37.524500Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"model = resnet18_cbam_with_SCN()\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.526520Z","iopub.execute_input":"2024-10-02T15:56:37.526801Z","iopub.status.idle":"2024-10-02T15:56:37.606135Z","shell.execute_reply.started":"2024-10-02T15:56:37.526771Z","shell.execute_reply":"2024-10-02T15:56:37.604956Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_29/937680273.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(r\"/kaggle/input/1head-pretrained-weights/1head_unfreeze_tot20epoch_4heads_epoch_12_acc_78.32.pth\")\n","output_type":"stream"}]},{"cell_type":"code","source":"modified_train = pd.read_csv(r\"/kaggle/input/scn-dataset/FER-Dataset/train_labels.csv\")\n# modified_train['label'] = modified_train['label']-1\nprint(modified_train['label'].max())\nprint(modified_train['label'].min())\n# modified_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.609976Z","iopub.execute_input":"2024-10-02T15:56:37.610390Z","iopub.status.idle":"2024-10-02T15:56:37.636044Z","shell.execute_reply.started":"2024-10-02T15:56:37.610347Z","shell.execute_reply":"2024-10-02T15:56:37.634978Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"6\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"modified_test = pd.read_csv(r\"/kaggle/input/scn-dataset/FER-Dataset/test_labels.csv\")\n# modifiedagg_test['label'] = modified_test['label']-1\nprint(modified_test['label'].max())\nprint(modified_test['label'].min())","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.637316Z","iopub.execute_input":"2024-10-02T15:56:37.637919Z","iopub.status.idle":"2024-10-02T15:56:37.651006Z","shell.execute_reply.started":"2024-10-02T15:56:37.637872Z","shell.execute_reply":"2024-10-02T15:56:37.649615Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"6\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n\n        # Read the CSV file\n        self.data_frame = pd.read_csv(csv_file)\n\n        # Ensure the CSV file has columns 'filename' and 'class'\n        assert 'image' in self.data_frame.columns\n        assert 'label' in self.data_frame.columns\n        \n        self.labels = self.data_frame['label'].values\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        # Get the filename and class label\n        img_name = self.data_frame.iloc[idx, 0]  # Get the filename from the CSV\n        class_label = self.labels[idx]  # Get the class label from the CSV\n\n        # Construct the path to the image based on its class label\n#         class_folder = os.path.join(self.image_dir, str(class_label+1))  # Convert class label to string\n#         img_path = os.path.join(class_folder, img_name)\n        img_path = os.path.join(self.image_dir, img_name)\n\n        # Load the image\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n\n        return image, class_label, idx","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.652668Z","iopub.execute_input":"2024-10-02T15:56:37.653252Z","iopub.status.idle":"2024-10-02T15:56:37.661343Z","shell.execute_reply.started":"2024-10-02T15:56:37.653209Z","shell.execute_reply":"2024-10-02T15:56:37.660512Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.662516Z","iopub.execute_input":"2024-10-02T15:56:37.662887Z","iopub.status.idle":"2024-10-02T15:56:37.672970Z","shell.execute_reply.started":"2024-10-02T15:56:37.662842Z","shell.execute_reply":"2024-10-02T15:56:37.672020Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"os.makedirs('models', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.674156Z","iopub.execute_input":"2024-10-02T15:56:37.674537Z","iopub.status.idle":"2024-10-02T15:56:37.680655Z","shell.execute_reply.started":"2024-10-02T15:56:37.674495Z","shell.execute_reply":"2024-10-02T15:56:37.679757Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def run_training():\n\n    # args = parse_args()\n    # imagenet_pretrained = True\n    # res18 = ResNetWithSCN(pretrained = imagenet_pretrained, drop_rate = args.drop_rate)\n    model = resnet18_cbam_with_SCN()\n    model = model.to(device)\n    \n    # if not imagenet_pretrained:\n    #      for m in res18.modules():\n    #         initialize_weight_goog(m)\n            \n    # if args.pretrained:\n    #     print(\"Loading pretrained weights...\", args.pretrained) \n    #     pretrained = torch.load(args.pretrained)\n    #     pretrained_state_dict = pretrained['state_dict']\n    #     model_state_dict = res18.state_dict()\n    #     loaded_keys = 0\n    #     total_keys = 0\n    #     for key in pretrained_state_dict:\n    #         if  ((key=='module.fc.weight')|(key=='module.fc.bias')):\n    #             pass\n    #         else:    \n    #             model_state_dict[key] = pretrained_state_dict[key]\n    #             total_keys+=1\n    #             if key in model_state_dict:\n    #                 loaded_keys+=1\n    #     print(\"Loaded params num:\", loaded_keys)\n    #     print(\"Total params num:\", total_keys)\n    #     res18.load_state_dict(model_state_dict, strict = False)  \n        \n    # data_transforms = transforms.Compose([\n    #     transforms.ToPILImage(),\n    #     transforms.Resize((224, 224)),\n    #     transforms.ToTensor(),\n    #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n    #                              std=[0.229, 0.224, 0.225]),\n    #     transforms.RandomErasing(scale=(0.02,0.25))])\n\n#     transform = transforms.Compose([\n#         transforms.Resize((224, 224)),\n#         transforms.ToTensor(),\n#     ])\n    transform = transforms.Compose([\n#         transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(scale=(0.02,0.25))\n    ])\n    \n    # train_dataset = RafDataSet(args.raf_path, phase = 'train', transform = data_transforms, basic_aug = True)  \n    image_directory = r\"/kaggle/input/scn-dataset/FER-Dataset/DATASET/train\"  # Directory containing class subfolders\n    csv_file_path = r\"/kaggle/input/scn-dataset/FER-Dataset/train_labels.csv\"\n    train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)\n    train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4, pin_memory=True, shuffle=True)\n    \n    # print('Train set size:', train_dataset.__len__())\n    # train_loader = torch.utils.data.DataLoader(train_dataset,\n    #                                            batch_size = args.batch_size,\n    #                                            num_workers = args.workers,\n    #                                            shuffle = True,  \n    #                                            pin_memory = True)\n    test_image_directory = r\"/kaggle/input/scn-dataset/FER-Dataset/DATASET/test\"\n    test_csv_file_path = r\"/kaggle/input/scn-dataset/FER-Dataset/test_labels.csv\"\n    test_dataset = CustomImageDataset(test_image_directory, test_csv_file_path, transform)\n    test_loader = DataLoader(test_dataset, batch_size=64,shuffle=False)\n    # data_transforms_val = transforms.Compose([\n    #     transforms.ToPILImage(),\n    #     transforms.Resize((224, 224)),\n    #     transforms.ToTensor(),\n    #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n    #                              std=[0.229, 0.224, 0.225])])                                           \n    # val_dataset = RafDataSet(args.raf_path, phase = 'test', transform = data_transforms_val)    \n    # print('Validation set size:', val_dataset.__len__())\n    \n    # val_loader = torch.utils.data.DataLoader(val_dataset,\n    #                                            batch_size = args.batch_size,\n    #                                            num_workers = args.workers,\n    #                                            shuffle = False,  \n    #                                            pin_memory = True)\n    \n    params = model.parameters()\n    criterion = nn.CrossEntropyLoss()\n#     optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n    optimizer = torch.optim.Adam(params,weight_decay = 1e-4)\n    \n    # if args.optimizer == 'adam':\n    #     optimizer = torch.optim.Adam(params,weight_decay = 1e-4)\n    # elif args.optimizer == 'sgd':\n    #     optimizer = torch.optim.SGD(params, args.lr,\n    #                                 momentum=args.momentum,\n    #                                 weight_decay = 1e-4)\n    # else:\n    #     raise ValueError(\"Optimizer not supported.\")\n    \n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n    # res18 = res18.cuda()\n    # criterion = torch.nn.CrossEntropyLoss()\n    \n    margin_1 = 0.15\n    margin_2 = 0.20\n    beta = 0.7\n    \n    for i in range(1, 20 + 1):\n        running_loss = 0.0\n        correct_sum = 0\n        iter_cnt = 0\n        best_acc = 0.75\n        model.train()\n        # for batch_i, (imgs, targets, indexes) in enumerate(train_loader):\n        for images, labels, indexes in tqdm(train_loader):\n            batch_sz = images.size(0) \n            iter_cnt += 1\n            tops = int(batch_sz* beta)\n            optimizer.zero_grad()\n            # imgs = imgs.cuda()\n            images = images.to(device) \n            labels = labels.to(device)\n            attention_weights, outputs = model(images)\n            \n            # Rank Regularization\n            _, top_idx = torch.topk(attention_weights.squeeze(), tops)\n            _, down_idx = torch.topk(attention_weights.squeeze(), batch_sz - tops, largest = False)\n\n            high_group = attention_weights[top_idx]\n            low_group = attention_weights[down_idx]\n            high_mean = torch.mean(high_group)\n            low_mean = torch.mean(low_group)\n            # diff  = margin_1 - (high_mean - low_mean)\n            diff  = low_mean - high_mean + margin_1\n\n            if diff > 0:\n                RR_loss = diff\n            else:\n                RR_loss = 0.0\n            \n            # targets = targets.cuda()\n            loss = criterion(outputs, labels) + RR_loss \n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss\n            _, predicts = torch.max(outputs, 1)\n            correct_num = torch.eq(predicts, labels).sum()\n            correct_sum += correct_num\n\n            # Relabel samples\n            if i >= 10:\n                sm = torch.softmax(outputs, dim = 1)\n                Pmax, predicted_labels = torch.max(sm, 1) # predictions\n                Pgt = torch.gather(sm, 1, labels.view(-1,1)).squeeze() # retrieve predicted probabilities of targets\n                true_or_false = Pmax - Pgt > margin_2\n                update_idx = true_or_false.nonzero().squeeze() # get samples' index in this mini-batch where (Pmax - Pgt > margin_2)\n                label_idx = indexes[update_idx.cpu()] # get samples' index in train_loader\n                relabels = predicted_labels[update_idx] # predictions where (Pmax - Pgt > margin_2)\n                train_loader.dataset.labels[label_idx.cpu().numpy()] = relabels.cpu().numpy() # relabel samples in train_loader\n                \n        scheduler.step()\n        acc = correct_sum.float() / float(train_dataset.__len__())\n        running_loss = running_loss/iter_cnt\n        print('[Epoch %d] Training accuracy: %.4f. Loss: %.3f' % (i, acc, running_loss))\n        \n        with torch.no_grad():\n            running_loss = 0.0\n            iter_cnt = 0\n            bingo_cnt = 0\n            sample_cnt = 0\n            model.eval()\n            # for batch_i, (imgs, targets, _) in enumerate(val_loader):\n            for imgs, targets, _ in tqdm(test_loader):\n                _, outputs = model(imgs.cuda())\n                targets = targets.cuda()\n                loss = criterion(outputs, targets)\n                running_loss += loss\n                iter_cnt+=1\n                _, predicts = torch.max(outputs, 1)\n                correct_num  = torch.eq(predicts,targets)\n                bingo_cnt += correct_num.sum().cpu()\n                sample_cnt += outputs.size(0)\n                \n            running_loss = running_loss/iter_cnt   \n            acc = bingo_cnt.float()/float(sample_cnt)\n            acc = np.around(acc.numpy(),4)\n            print(\"[Epoch %d] Test accuracy:%.4f. Loss:%.3f\" % (i, acc, running_loss))\n           \n            if acc > best_acc :\n                best_acc = acc\n                torch.save({'iter': i,\n                            'model_state_dict': model.state_dict(),\n                             'optimizer_state_dict': optimizer.state_dict(),},\n                            os.path.join('models', \"1head_SCN_epoch_\"+str(i)+\"_acc_\"+str(acc)+\".pth\"))\n                print('Model saved.')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.682177Z","iopub.execute_input":"2024-10-02T15:56:37.682697Z","iopub.status.idle":"2024-10-02T15:56:37.709725Z","shell.execute_reply.started":"2024-10-02T15:56:37.682656Z","shell.execute_reply":"2024-10-02T15:56:37.708898Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# ### Continuation from epoch 20 \n\n\n\n\n\n\n\n# def run_training():\n\n#     # args = parse_args()\n#     # imagenet_pretrained = True\n#     # res18 = ResNetWithSCN(pretrained = imagenet_pretrained, drop_rate = args.drop_rate)\n#     model = resnet18_cbam_with_SCN()\n#     model = model.to(device)\n    \n#     # if not imagenet_pretrained:\n#     #      for m in res18.modules():\n#     #         initialize_weight_goog(m)\n            \n#     # if args.pretrained:\n#     #     print(\"Loading pretrained weights...\", args.pretrained) \n#     #     pretrained = torch.load(args.pretrained)\n#     #     pretrained_state_dict = pretrained['state_dict']\n#     #     model_state_dict = res18.state_dict()\n#     #     loaded_keys = 0\n#     #     total_keys = 0\n#     #     for key in pretrained_state_dict:\n#     #         if  ((key=='module.fc.weight')|(key=='module.fc.bias')):\n#     #             pass\n#     #         else:    \n#     #             model_state_dict[key] = pretrained_state_dict[key]\n#     #             total_keys+=1\n#     #             if key in model_state_dict:\n#     #                 loaded_keys+=1\n#     #     print(\"Loaded params num:\", loaded_keys)\n#     #     print(\"Total params num:\", total_keys)\n#     #     res18.load_state_dict(model_state_dict, strict = False)  \n        \n#     # data_transforms = transforms.Compose([\n#     #     transforms.ToPILImage(),\n#     #     transforms.Resize((224, 224)),\n#     #     transforms.ToTensor(),\n#     #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#     #                              std=[0.229, 0.224, 0.225]),\n#     #     transforms.RandomErasing(scale=(0.02,0.25))])\n\n# #     transform = transforms.Compose([\n# #         transforms.Resize((224, 224)),\n# #         transforms.ToTensor(),\n# #     ])\n#     transform = transforms.Compose([\n# #         transforms.ToPILImage(),\n#         transforms.Resize((224, 224)),\n#         transforms.ToTensor(),\n#         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                                  std=[0.229, 0.224, 0.225]),\n#         transforms.RandomErasing(scale=(0.02,0.25))\n#     ])\n    \n#     # train_dataset = RafDataSet(args.raf_path, phase = 'train', transform = data_transforms, basic_aug = True)  \n#     image_directory = r\"/kaggle/input/scn-dataset/FER-Dataset/DATASET/train\"  # Directory containing class subfolders\n#     csv_file_path = r\"/kaggle/input/scn-dataset/FER-Dataset/train_labels.csv\"\n#     train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)\n#     train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4, pin_memory=True, shuffle=True)\n    \n#     # print('Train set size:', train_dataset.__len__())\n#     # train_loader = torch.utils.data.DataLoader(train_dataset,\n#     #                                            batch_size = args.batch_size,\n#     #                                            num_workers = args.workers,\n#     #                                            shuffle = True,  \n#     #                                            pin_memory = True)\n#     test_image_directory = r\"/kaggle/input/scn-dataset/FER-Dataset/DATASET/test\"\n#     test_csv_file_path = r\"/kaggle/input/scn-dataset/FER-Dataset/test_labels.csv\"\n#     test_dataset = CustomImageDataset(test_image_directory, test_csv_file_path, transform)\n#     test_loader = DataLoader(test_dataset, batch_size=64,shuffle=False)\n#     # data_transforms_val = transforms.Compose([\n#     #     transforms.ToPILImage(),\n#     #     transforms.Resize((224, 224)),\n#     #     transforms.ToTensor(),\n#     #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#     #                              std=[0.229, 0.224, 0.225])])                                           \n#     # val_dataset = RafDataSet(args.raf_path, phase = 'test', transform = data_transforms_val)    \n#     # print('Validation set size:', val_dataset.__len__())\n    \n#     # val_loader = torch.utils.data.DataLoader(val_dataset,\n#     #                                            batch_size = args.batch_size,\n#     #                                            num_workers = args.workers,\n#     #                                            shuffle = False,  \n#     #                                            pin_memory = True)\n    \n#     params = model.parameters()\n#     criterion = nn.CrossEntropyLoss()\n# #     optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n#     optimizer = torch.optim.Adam(params,weight_decay = 1e-4)\n    \n#     # if args.optimizer == 'adam':\n#     #     optimizer = torch.optim.Adam(params,weight_decay = 1e-4)\n#     # elif args.optimizer == 'sgd':\n#     #     optimizer = torch.optim.SGD(params, args.lr,\n#     #                                 momentum=args.momentum,\n#     #                                 weight_decay = 1e-4)\n#     # else:\n#     #     raise ValueError(\"Optimizer not supported.\")\n    \n#     scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n#     # res18 = res18.cuda()\n#     # criterion = torch.nn.CrossEntropyLoss()\n    \n#     margin_1 = 0.15\n#     margin_2 = 0.20\n#     beta = 0.7\n#     best_acc = 0.78\n#     for i in range(1, 20 + 1):\n#         running_loss = 0.0\n#         correct_sum = 0\n#         iter_cnt = 0\n#         best_acc = 0.75\n#         model.train()\n#         # for batch_i, (imgs, targets, indexes) in enumerate(train_loader):\n#         for images, labels, indexes in tqdm(train_loader):\n#             batch_sz = images.size(0) \n#             iter_cnt += 1\n#             tops = int(batch_sz* beta)\n#             optimizer.zero_grad()\n#             # imgs = imgs.cuda()\n#             images = images.to(device) \n#             labels = labels.to(device)\n#             attention_weights, outputs = model(images)\n            \n#             # Rank Regularization\n#             _, top_idx = torch.topk(attention_weights.squeeze(), tops)\n#             _, down_idx = torch.topk(attention_weights.squeeze(), batch_sz - tops, largest = False)\n\n#             high_group = attention_weights[top_idx]\n#             low_group = attention_weights[down_idx]\n#             high_mean = torch.mean(high_group)\n#             low_mean = torch.mean(low_group)\n#             # diff  = margin_1 - (high_mean - low_mean)\n#             diff  = low_mean - high_mean + margin_1\n\n#             if diff > 0:\n#                 RR_loss = diff\n#             else:\n#                 RR_loss = 0.0\n            \n#             # targets = targets.cuda()\n#             loss = criterion(outputs, labels) + RR_loss \n#             loss.backward()\n#             optimizer.step()\n            \n#             running_loss += loss\n#             _, predicts = torch.max(outputs, 1)\n#             correct_num = torch.eq(predicts, labels).sum()\n#             correct_sum += correct_num\n\n#             # Relabel samples\n#             if i >= 10:\n#                 sm = torch.softmax(outputs, dim = 1)\n#                 Pmax, predicted_labels = torch.max(sm, 1) # predictions\n#                 Pgt = torch.gather(sm, 1, labels.view(-1,1)).squeeze() # retrieve predicted probabilities of targets\n#                 true_or_false = Pmax - Pgt > margin_2\n#                 update_idx = true_or_false.nonzero().squeeze() # get samples' index in this mini-batch where (Pmax - Pgt > margin_2)\n#                 label_idx = indexes[update_idx.cpu()] # get samples' index in train_loader\n#                 relabels = predicted_labels[update_idx] # predictions where (Pmax - Pgt > margin_2)\n#                 train_loader.dataset.labels[label_idx.cpu().numpy()] = relabels.cpu().numpy() # relabel samples in train_loader\n                \n#         scheduler.step()\n#         acc = correct_sum.float() / float(train_dataset.__len__())\n#         running_loss = running_loss/iter_cnt\n#         print('[Epoch %d] Training accuracy: %.4f. Loss: %.3f' % (i, acc, running_loss))\n        \n#         with torch.no_grad():\n#             running_loss = 0.0\n#             iter_cnt = 0\n#             bingo_cnt = 0\n#             sample_cnt = 0\n#             model.eval()\n#             # for batch_i, (imgs, targets, _) in enumerate(val_loader):\n#             for imgs, targets, _ in tqdm(test_loader):\n#                 _, outputs = model(imgs.cuda())\n#                 targets = targets.cuda()\n#                 loss = criterion(outputs, targets)\n#                 running_loss += loss\n#                 iter_cnt+=1\n#                 _, predicts = torch.max(outputs, 1)\n#                 correct_num  = torch.eq(predicts,targets)\n#                 bingo_cnt += correct_num.sum().cpu()\n#                 sample_cnt += outputs.size(0)\n                \n#             running_loss = running_loss/iter_cnt   \n#             acc = bingo_cnt.float()/float(sample_cnt)\n#             acc = np.around(acc.numpy(),4)\n#             print(\"[Epoch %d] Test accuracy:%.4f. Loss:%.3f\" % (i, acc, running_loss))\n           \n#             if acc > best_acc :\n#                 best_acc = acc\n#                 torch.save({'iter': i,\n#                             'model_state_dict': model.state_dict(),\n#                              'optimizer_state_dict': optimizer.state_dict(),},\n#                             os.path.join('models', \"1head_SCN_epoch_\"+str(i)+\"_acc_\"+str(acc)+\".pth\"))\n#                 print('Model saved.')\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-02T16:20:15.802309Z","iopub.execute_input":"2024-10-02T16:20:15.802749Z","iopub.status.idle":"2024-10-02T16:20:15.816210Z","shell.execute_reply.started":"2024-10-02T16:20:15.802708Z","shell.execute_reply":"2024-10-02T16:20:15.815182Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def new_run_training(model):\n#     model = resnet18_cbam_with_SCN()\n    model = model.to(device)\n    transform = transforms.Compose([\n#         transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(scale=(0.02,0.25))\n    ])\n    \n    image_directory = r\"/kaggle/input/scn-dataset/FER-Dataset/DATASET/train\"  # Directory containing class subfolders\n    csv_file_path = r\"/kaggle/input/scn-dataset/FER-Dataset/train_labels.csv\"\n    train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)\n    train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4, pin_memory=True, shuffle=True)\n   \n    test_image_directory = r\"/kaggle/input/scn-dataset/FER-Dataset/DATASET/test\"\n    test_csv_file_path = r\"/kaggle/input/scn-dataset/FER-Dataset/test_labels.csv\"\n    test_dataset = CustomImageDataset(test_image_directory, test_csv_file_path, transform)\n    test_loader = DataLoader(test_dataset, batch_size=64,shuffle=False)\n    \n    params = model.parameters()\n    criterion = nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.Adam(params,weight_decay = 1e-4)\n   \n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n    \n    \n    margin_1 = 0.15\n    margin_2 = 0.20\n    beta = 0.7\n    best_acc = 0.78\n    for i in range(41, 60 + 1):\n        running_loss = 0.0\n        correct_sum = 0\n        iter_cnt = 0\n#         best_acc = 0.75\n        model.train()\n        # for batch_i, (imgs, targets, indexes) in enumerate(train_loader):\n        for images, labels, indexes in tqdm(train_loader):\n            batch_sz = images.size(0) \n            iter_cnt += 1\n            tops = int(batch_sz* beta)\n            optimizer.zero_grad()\n            # imgs = imgs.cuda()\n            images = images.to(device) \n            labels = labels.to(device)\n            attention_weights, outputs = model(images)\n            \n            # Rank Regularization\n            _, top_idx = torch.topk(attention_weights.squeeze(), tops)\n            _, down_idx = torch.topk(attention_weights.squeeze(), batch_sz - tops, largest = False)\n\n            high_group = attention_weights[top_idx]\n            low_group = attention_weights[down_idx]\n            high_mean = torch.mean(high_group)\n            low_mean = torch.mean(low_group)\n            # diff  = margin_1 - (high_mean - low_mean)\n            diff  = low_mean - high_mean + margin_1\n\n            if diff > 0:\n                RR_loss = diff\n            else:\n                RR_loss = 0.0\n            \n            # targets = targets.cuda()\n            loss = criterion(outputs, labels) + RR_loss \n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss\n            _, predicts = torch.max(outputs, 1)\n            correct_num = torch.eq(predicts, labels).sum()\n            correct_sum += correct_num\n\n            # Relabel samples\n            if i >= 21:\n                sm = torch.softmax(outputs, dim = 1)\n                Pmax, predicted_labels = torch.max(sm, 1) # predictions\n                Pgt = torch.gather(sm, 1, labels.view(-1,1)).squeeze() # retrieve predicted probabilities of targets\n                true_or_false = Pmax - Pgt > margin_2\n                update_idx = true_or_false.nonzero().squeeze() # get samples' index in this mini-batch where (Pmax - Pgt > margin_2)\n                label_idx = indexes[update_idx.cpu()] # get samples' index in train_loader\n                relabels = predicted_labels[update_idx] # predictions where (Pmax - Pgt > margin_2)\n                train_loader.dataset.labels[label_idx.cpu().numpy()] = relabels.cpu().numpy() # relabel samples in train_loader\n                \n        scheduler.step()\n        acc = correct_sum.float() / float(train_dataset.__len__())\n        running_loss = running_loss/iter_cnt\n        print('[Epoch %d] Training accuracy: %.4f. Loss: %.3f' % (i, acc, running_loss))\n        \n        with torch.no_grad():\n            running_loss = 0.0\n            iter_cnt = 0\n            bingo_cnt = 0\n            sample_cnt = 0\n            model.eval()\n            # for batch_i, (imgs, targets, _) in enumerate(val_loader):\n            for imgs, targets, _ in tqdm(test_loader):\n                _, outputs = model(imgs.cuda())\n                targets = targets.cuda()\n                loss = criterion(outputs, targets)\n                running_loss += loss\n                iter_cnt+=1\n                _, predicts = torch.max(outputs, 1)\n                correct_num  = torch.eq(predicts,targets)\n                bingo_cnt += correct_num.sum().cpu()\n                sample_cnt += outputs.size(0)\n                \n            running_loss = running_loss/iter_cnt   \n            acc = bingo_cnt.float()/float(sample_cnt)\n            acc = np.around(acc.numpy(),4)\n            print(\"[Epoch %d] Test accuracy:%.4f. Loss:%.3f\" % (i, acc, running_loss))\n           \n            if acc > best_acc :\n                best_acc = acc\n                torch.save({'iter': i,\n                            'model_state_dict': model.state_dict(),\n                             'optimizer_state_dict': optimizer.state_dict(),},\n                            os.path.join('models', \"1head_SCN_epoch_\"+str(i)+\"_acc_\"+str(acc)+\".pth\"))\n                print('Model saved.')","metadata":{"execution":{"iopub.status.busy":"2024-10-02T19:39:20.581511Z","iopub.execute_input":"2024-10-02T19:39:20.582306Z","iopub.status.idle":"2024-10-02T19:39:20.606698Z","shell.execute_reply.started":"2024-10-02T19:39:20.582264Z","shell.execute_reply":"2024-10-02T19:39:20.605674Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"new_run_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-02T19:39:25.501465Z","iopub.execute_input":"2024-10-02T19:39:25.502338Z","iopub.status.idle":"2024-10-02T19:39:25.529651Z","shell.execute_reply.started":"2024-10-02T19:39:25.502294Z","shell.execute_reply":"2024-10-02T19:39:25.528154Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_run_training(\u001b[43mmodel\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"run_training()","metadata":{"execution":{"iopub.status.busy":"2024-10-02T15:56:37.711803Z","iopub.execute_input":"2024-10-02T15:56:37.712085Z","iopub.status.idle":"2024-10-02T16:12:52.949348Z","shell.execute_reply.started":"2024-10-02T15:56:37.712055Z","shell.execute_reply":"2024-10-02T16:12:52.948285Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_29/937680273.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(r\"/kaggle/input/1head-pretrained-weights/1head_unfreeze_tot20epoch_4heads_epoch_12_acc_78.32.pth\")\n100%|██████████| 192/192 [00:34<00:00,  5.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Training accuracy: 0.8303. Loss: 0.510\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:25<00:00,  1.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Test accuracy:0.7568. Loss:0.822\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Training accuracy: 0.8614. Loss: 0.417\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:15<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Test accuracy:0.7057. Loss:0.920\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Training accuracy: 0.8804. Loss: 0.366\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:15<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Test accuracy:0.7262. Loss:0.960\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Training accuracy: 0.8954. Loss: 0.316\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:16<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Test accuracy:0.7379. Loss:0.911\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Training accuracy: 0.9068. Loss: 0.285\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Test accuracy:0.7484. Loss:0.927\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Training accuracy: 0.9188. Loss: 0.250\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Test accuracy:0.7415. Loss:1.043\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Training accuracy: 0.9240. Loss: 0.230\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Test accuracy:0.7520. Loss:1.045\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Training accuracy: 0.9316. Loss: 0.208\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Test accuracy:0.7409. Loss:1.026\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Training accuracy: 0.9425. Loss: 0.185\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Test accuracy:0.7441. Loss:1.078\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Training accuracy: 0.9426. Loss: 0.181\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Test accuracy:0.7549. Loss:1.061\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Training accuracy: 0.9108. Loss: 0.370\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Test accuracy:0.7702. Loss:0.856\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Training accuracy: 0.9196. Loss: 0.311\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Test accuracy:0.7702. Loss:0.824\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Training accuracy: 0.9192. Loss: 0.304\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Test accuracy:0.7637. Loss:0.874\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Training accuracy: 0.9202. Loss: 0.293\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Test accuracy:0.7715. Loss:0.809\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Training accuracy: 0.9209. Loss: 0.295\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Test accuracy:0.7581. Loss:0.791\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Training accuracy: 0.9254. Loss: 0.277\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Test accuracy:0.7699. Loss:0.825\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Training accuracy: 0.9306. Loss: 0.262\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Test accuracy:0.7754. Loss:0.803\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Training accuracy: 0.9331. Loss: 0.252\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Test accuracy:0.7702. Loss:0.811\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Training accuracy: 0.9309. Loss: 0.252\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:13<00:00,  3.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Test accuracy:0.7715. Loss:0.833\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Training accuracy: 0.9333. Loss: 0.256\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:14<00:00,  3.40it/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Test accuracy:0.7832. Loss:0.787\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}