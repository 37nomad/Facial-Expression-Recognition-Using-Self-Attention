{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654},{"sourceId":9525077,"sourceType":"datasetVersion","datasetId":5800053},{"sourceId":9525123,"sourceType":"datasetVersion","datasetId":5800087},{"sourceId":9525407,"sourceType":"datasetVersion","datasetId":5800298}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport numpy as np \nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.230587Z","iopub.execute_input":"2024-10-01T16:35:55.231295Z","iopub.status.idle":"2024-10-01T16:35:55.237629Z","shell.execute_reply.started":"2024-10-01T16:35:55.231254Z","shell.execute_reply":"2024-10-01T16:35:55.236662Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# def initialize_weight_goog(m):\n#     if isinstance(m, nn.Linear):\n#         fan_out = m.weight.size(0)\n#         fan_in = 0\n#         init_range = 1.0 / math.sqrt(fan_in + fan_out)\n#         m.weight.data.uniform_(-init_range, init_range)\n#         m.bias.data.zero_(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.244204Z","iopub.execute_input":"2024-10-01T16:35:55.244977Z","iopub.status.idle":"2024-10-01T16:35:55.251042Z","shell.execute_reply.started":"2024-10-01T16:35:55.244939Z","shell.execute_reply":"2024-10-01T16:35:55.250188Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.260865Z","iopub.execute_input":"2024-10-01T16:35:55.261161Z","iopub.status.idle":"2024-10-01T16:35:55.266678Z","shell.execute_reply.started":"2024-10-01T16:35:55.261109Z","shell.execute_reply":"2024-10-01T16:35:55.265539Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.280648Z","iopub.execute_input":"2024-10-01T16:35:55.280985Z","iopub.status.idle":"2024-10-01T16:35:55.288955Z","shell.execute_reply.started":"2024-10-01T16:35:55.280954Z","shell.execute_reply":"2024-10-01T16:35:55.288169Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.294796Z","iopub.execute_input":"2024-10-01T16:35:55.295093Z","iopub.status.idle":"2024-10-01T16:35:55.302404Z","shell.execute_reply.started":"2024-10-01T16:35:55.295050Z","shell.execute_reply":"2024-10-01T16:35:55.301468Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.ca = ChannelAttention(planes)\n        self.sa = SpatialAttention()\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out = self.ca(out) * out\n        out = self.sa(out) * out\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.310180Z","iopub.execute_input":"2024-10-01T16:35:55.310441Z","iopub.status.idle":"2024-10-01T16:35:55.318957Z","shell.execute_reply.started":"2024-10-01T16:35:55.310412Z","shell.execute_reply":"2024-10-01T16:35:55.318051Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class ResNetWithSCN(nn.Module):\n\n    def __init__(self, block, layers, num_heads, num_classes=7):\n        self.inplanes = 64\n        # self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        super(ResNetWithSCN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n        self.attention = nn.MultiheadAttention(256, num_heads)\n        self.layer_norm = nn.LayerNorm(256)\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.linear1 = nn.Linear(256,128)\n        self.relu1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(0.5)   \n        self.classifier = nn.Linear(128, num_classes)\n            # nn.Linear(256,128),\n            # nn.ReLU(),\n            # nn.Dropout(0.5),\n            # nn.Linear(128, num_classes)\n        \n        self.alpha = nn.Sequential(\n            # nn.Linear(256,128),\n            # nn.ReLU(),\n            # nn.Dropout(0.5),\n            # nn.Linear(128, num_classes)\n            nn.Linear(128,1),\n            nn.Sigmoid()\n        )\n\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                fan_out = m.weight.size(0)  # fan-out\n                fan_in = m.weight.size(1) if m.weight.dim() > 1 else 0  # fan-in\n                init_range = 1.0 / math.sqrt(fan_in + fan_out)\n                m.weight.data.uniform_(-init_range, init_range)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n        for m in self.alpha.modules():\n            if isinstance(m, nn.Linear):\n                fan_out = m.weight.size(0)  # fan-out\n                fan_in = m.weight.size(1) if m.weight.dim() > 1 else 0  # fan-in\n                init_range = 1.0 / math.sqrt(fan_in + fan_out)\n                m.weight.data.uniform_(-init_range, init_range)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        # x = self.layer4(x)\n\n        # x = self.avgpool(x)\n        # x = x.view(x.size(0), -1)\n        # x = self.fc(x)\n        batch_size, channels, height, width = x.shape\n        x = x.view(batch_size, channels, height*width).permute(0,2,1)\n\n        query = x\n        key = x\n        value = x\n\n        attn_output, _ = self.attention(query, key, value)\n        x = self.layer_norm(attn_output + x)\n        x = x.permute(0,2,1).view(batch_size, channels, height, width)\n        # x = nn.functional.adaptive_avg_pool2d(x,1).view(batch_size, -1)\n        x = self.global_avg_pool(x).view(batch_size, -1)\n        x = self.linear1(x)\n        x = self.relu1(x)\n        x = self.dropout1(x)\n        \n        attention_weights = self.alpha(x)\n        out = attention_weights * self.classifier(x)\n\n        return attention_weights, out","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:35:55.331944Z","iopub.execute_input":"2024-10-01T16:35:55.332244Z","iopub.status.idle":"2024-10-01T16:35:55.354306Z","shell.execute_reply.started":"2024-10-01T16:35:55.332212Z","shell.execute_reply":"2024-10-01T16:35:55.353338Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def resnet18_cbam_with_SCN(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    num_heads = 4\n    model = ResNetWithSCN(BasicBlock, [2, 2, 2, 2], num_heads)\n    # if pretrained:\n    #     pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n    #     now_state_dict        = model.state_dict()\n    #     now_state_dict.update(pretrained_state_dict)\n    #     model.load_state_dict(now_state_dict, strict=False)\n    \n    # New Code Starts From Here\n    if pretrained:\n        checkpoint = torch.load(r\"/kaggle/working/models/SCN1_epoch_3_acc_0.7741.pth\")\n        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n    # Ends Here\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:05.338718Z","iopub.execute_input":"2024-10-01T16:57:05.339143Z","iopub.status.idle":"2024-10-01T16:57:05.346070Z","shell.execute_reply.started":"2024-10-01T16:57:05.339094Z","shell.execute_reply":"2024-10-01T16:57:05.345012Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:06.988080Z","iopub.execute_input":"2024-10-01T16:57:06.988493Z","iopub.status.idle":"2024-10-01T16:57:06.996319Z","shell.execute_reply.started":"2024-10-01T16:57:06.988458Z","shell.execute_reply":"2024-10-01T16:57:06.995321Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"model = resnet18_cbam_with_SCN()\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:08.028908Z","iopub.execute_input":"2024-10-01T16:57:08.029315Z","iopub.status.idle":"2024-10-01T16:57:08.151115Z","shell.execute_reply.started":"2024-10-01T16:57:08.029264Z","shell.execute_reply":"2024-10-01T16:57:08.150174Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2129379240.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(r\"/kaggle/working/models/SCN1_epoch_3_acc_0.7741.pth\")\n","output_type":"stream"}]},{"cell_type":"code","source":"modified_train = pd.read_csv(r\"/kaggle/input/check-this-dataset/FER-Dataset/train_labels.csv\")\n# modified_train['label'] = modified_train['label']-1\nprint(modified_train['label'].max())\nprint(modified_train['label'].min())\n# modified_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:11.840798Z","iopub.execute_input":"2024-10-01T16:57:11.841636Z","iopub.status.idle":"2024-10-01T16:57:11.861409Z","shell.execute_reply.started":"2024-10-01T16:57:11.841594Z","shell.execute_reply":"2024-10-01T16:57:11.860440Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"6\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"modified_test = pd.read_csv(r\"/kaggle/input/check-this-dataset/FER-Dataset/test_labels.csv\")\n# modifiedagg_test['label'] = modified_test['label']-1\nprint(modified_test['label'].max())\nprint(modified_test['label'].min())","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:12.564343Z","iopub.execute_input":"2024-10-01T16:57:12.564990Z","iopub.status.idle":"2024-10-01T16:57:12.575420Z","shell.execute_reply.started":"2024-10-01T16:57:12.564954Z","shell.execute_reply":"2024-10-01T16:57:12.574348Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"6\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n\n        # Read the CSV file\n        self.data_frame = pd.read_csv(csv_file)\n\n        # Ensure the CSV file has columns 'filename' and 'class'\n        assert 'image' in self.data_frame.columns\n        assert 'label' in self.data_frame.columns\n        \n        self.labels = self.data_frame['label'].values\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        # Get the filename and class label\n        img_name = self.data_frame.iloc[idx, 0]  # Get the filename from the CSV\n        class_label = self.labels[idx]  # Get the class label from the CSV\n\n        # Construct the path to the image based on its class label\n#         class_folder = os.path.join(self.image_dir, str(class_label+1))  # Convert class label to string\n#         img_path = os.path.join(class_folder, img_name)\n        img_path = os.path.join(self.image_dir, img_name)\n\n        # Load the image\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n\n        return image, class_label, idx","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:13.665607Z","iopub.execute_input":"2024-10-01T16:57:13.666210Z","iopub.status.idle":"2024-10-01T16:57:13.674574Z","shell.execute_reply.started":"2024-10-01T16:57:13.666170Z","shell.execute_reply":"2024-10-01T16:57:13.673629Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:17.214382Z","iopub.execute_input":"2024-10-01T16:57:17.214803Z","iopub.status.idle":"2024-10-01T16:57:17.221382Z","shell.execute_reply.started":"2024-10-01T16:57:17.214764Z","shell.execute_reply":"2024-10-01T16:57:17.220387Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"os.makedirs('models', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:17.873143Z","iopub.execute_input":"2024-10-01T16:57:17.874060Z","iopub.status.idle":"2024-10-01T16:57:17.878325Z","shell.execute_reply.started":"2024-10-01T16:57:17.874019Z","shell.execute_reply":"2024-10-01T16:57:17.877204Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def run_training():\n\n    # args = parse_args()\n    # imagenet_pretrained = True\n    # res18 = ResNetWithSCN(pretrained = imagenet_pretrained, drop_rate = args.drop_rate)\n    model = resnet18_cbam_with_SCN()\n    model.to(device)\n    \n    # if not imagenet_pretrained:\n    #      for m in res18.modules():\n    #         initialize_weight_goog(m)\n            \n    # if args.pretrained:\n    #     print(\"Loading pretrained weights...\", args.pretrained) \n    #     pretrained = torch.load(args.pretrained)\n    #     pretrained_state_dict = pretrained['state_dict']\n    #     model_state_dict = res18.state_dict()\n    #     loaded_keys = 0\n    #     total_keys = 0\n    #     for key in pretrained_state_dict:\n    #         if  ((key=='module.fc.weight')|(key=='module.fc.bias')):\n    #             pass\n    #         else:    \n    #             model_state_dict[key] = pretrained_state_dict[key]\n    #             total_keys+=1\n    #             if key in model_state_dict:\n    #                 loaded_keys+=1\n    #     print(\"Loaded params num:\", loaded_keys)\n    #     print(\"Total params num:\", total_keys)\n    #     res18.load_state_dict(model_state_dict, strict = False)  \n        \n    # data_transforms = transforms.Compose([\n    #     transforms.ToPILImage(),\n    #     transforms.Resize((224, 224)),\n    #     transforms.ToTensor(),\n    #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n    #                              std=[0.229, 0.224, 0.225]),\n    #     transforms.RandomErasing(scale=(0.02,0.25))])\n\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n    \n    # train_dataset = RafDataSet(args.raf_path, phase = 'train', transform = data_transforms, basic_aug = True)  \n    image_directory = r\"/kaggle/input/check-this-dataset/FER-Dataset/DATASET/train\"  # Directory containing class subfolders\n    csv_file_path = r\"/kaggle/input/check-this-dataset/FER-Dataset/train_labels.csv\"\n    train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)\n    train_loader = DataLoader(train_dataset, batch_size=32, num_workers=4, pin_memory=True, shuffle=True)\n    \n    # print('Train set size:', train_dataset.__len__())\n    # train_loader = torch.utils.data.DataLoader(train_dataset,\n    #                                            batch_size = args.batch_size,\n    #                                            num_workers = args.workers,\n    #                                            shuffle = True,  \n    #                                            pin_memory = True)\n    test_image_directory = r\"/kaggle/input/check-this-dataset/FER-Dataset/DATASET/test\"\n    test_csv_file_path = r\"/kaggle/input/check-this-dataset/FER-Dataset/test_labels.csv\"\n    test_dataset = CustomImageDataset(test_image_directory, test_csv_file_path, transform)\n    test_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)\n    # data_transforms_val = transforms.Compose([\n    #     transforms.ToPILImage(),\n    #     transforms.Resize((224, 224)),\n    #     transforms.ToTensor(),\n    #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n    #                              std=[0.229, 0.224, 0.225])])                                           \n    # val_dataset = RafDataSet(args.raf_path, phase = 'test', transform = data_transforms_val)    \n    # print('Validation set size:', val_dataset.__len__())\n    \n    # val_loader = torch.utils.data.DataLoader(val_dataset,\n    #                                            batch_size = args.batch_size,\n    #                                            num_workers = args.workers,\n    #                                            shuffle = False,  \n    #                                            pin_memory = True)\n    \n    params = model.parameters()\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n    \n    # if args.optimizer == 'adam':\n    #     optimizer = torch.optim.Adam(params,weight_decay = 1e-4)\n    # elif args.optimizer == 'sgd':\n    #     optimizer = torch.optim.SGD(params, args.lr,\n    #                                 momentum=args.momentum,\n    #                                 weight_decay = 1e-4)\n    # else:\n    #     raise ValueError(\"Optimizer not supported.\")\n    \n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n    # res18 = res18.cuda()\n    # criterion = torch.nn.CrossEntropyLoss()\n    \n    margin_1 = 0.15\n    margin_2 = 0.20\n    beta = 0.7\n    \n    for i in range(1, 20 + 1):\n        running_loss = 0.0\n        correct_sum = 0\n        iter_cnt = 0\n        model.train()\n        # for batch_i, (imgs, targets, indexes) in enumerate(train_loader):\n        for images, labels, indexes in tqdm(train_loader):\n            batch_sz = images.size(0) \n            iter_cnt += 1\n            tops = int(batch_sz* beta)\n            optimizer.zero_grad()\n            # imgs = imgs.cuda()\n            images = images.to(device) \n            labels = labels.to(device)\n            attention_weights, outputs = model(images)\n            \n            # Rank Regularization\n            _, top_idx = torch.topk(attention_weights.squeeze(), tops)\n            _, down_idx = torch.topk(attention_weights.squeeze(), batch_sz - tops, largest = False)\n\n            high_group = attention_weights[top_idx]\n            low_group = attention_weights[down_idx]\n            high_mean = torch.mean(high_group)\n            low_mean = torch.mean(low_group)\n            # diff  = margin_1 - (high_mean - low_mean)\n            diff  = low_mean - high_mean + margin_1\n\n            if diff > 0:\n                RR_loss = diff\n            else:\n                RR_loss = 0.0\n            \n            # targets = targets.cuda()\n            loss = criterion(outputs, labels) + RR_loss \n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss\n            _, predicts = torch.max(outputs, 1)\n            correct_num = torch.eq(predicts, labels).sum()\n            correct_sum += correct_num\n\n            # Relabel samples\n            if i >= 10:\n                sm = torch.softmax(outputs, dim = 1)\n                Pmax, predicted_labels = torch.max(sm, 1) # predictions\n                Pgt = torch.gather(sm, 1, labels.view(-1,1)).squeeze() # retrieve predicted probabilities of targets\n                true_or_false = Pmax - Pgt > margin_2\n                update_idx = true_or_false.nonzero().squeeze() # get samples' index in this mini-batch where (Pmax - Pgt > margin_2)\n                label_idx = indexes[update_idx.cpu()] # get samples' index in train_loader\n                relabels = predicted_labels[update_idx] # predictions where (Pmax - Pgt > margin_2)\n                train_loader.dataset.labels[label_idx.cpu().numpy()] = relabels.cpu().numpy() # relabel samples in train_loader\n                \n        scheduler.step()\n        acc = correct_sum.float() / float(train_dataset.__len__())\n        running_loss = running_loss/iter_cnt\n        print('[Epoch %d] Training accuracy: %.4f. Loss: %.3f' % (i, acc, running_loss))\n        \n        with torch.no_grad():\n            running_loss = 0.0\n            iter_cnt = 0\n            bingo_cnt = 0\n            sample_cnt = 0\n            model.eval()\n            # for batch_i, (imgs, targets, _) in enumerate(val_loader):\n            for imgs, targets, _ in tqdm(test_loader):\n                _, outputs = model(imgs.cuda())\n                targets = targets.cuda()\n                loss = criterion(outputs, targets)\n                running_loss += loss\n                iter_cnt+=1\n                _, predicts = torch.max(outputs, 1)\n                correct_num  = torch.eq(predicts,targets)\n                bingo_cnt += correct_num.sum().cpu()\n                sample_cnt += outputs.size(0)\n                \n            running_loss = running_loss/iter_cnt   \n            acc = bingo_cnt.float()/float(sample_cnt)\n            acc = np.around(acc.numpy(),4)\n            print(\"[Epoch %d] Test accuracy:%.4f. Loss:%.3f\" % (i, acc, running_loss))\n           \n            if acc > 0.76 :\n                torch.save({'iter': i,\n                            'model_state_dict': model.state_dict(),\n                             'optimizer_state_dict': optimizer.state_dict(),},\n                            os.path.join('models', \"SCN2_epoch_\"+str(i)+\"_acc_\"+str(acc)+\".pth\"))\n                print('Model saved.')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:30.843511Z","iopub.execute_input":"2024-10-01T16:57:30.843961Z","iopub.status.idle":"2024-10-01T16:57:30.879651Z","shell.execute_reply.started":"2024-10-01T16:57:30.843918Z","shell.execute_reply":"2024-10-01T16:57:30.878575Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"run_training()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T16:57:32.138948Z","iopub.execute_input":"2024-10-01T16:57:32.139734Z","iopub.status.idle":"2024-10-01T17:14:21.546372Z","shell.execute_reply.started":"2024-10-01T16:57:32.139692Z","shell.execute_reply":"2024-10-01T17:14:21.545227Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2129379240.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(r\"/kaggle/working/models/SCN1_epoch_3_acc_0.7741.pth\")\n100%|██████████| 384/384 [00:40<00:00,  9.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Training accuracy: 0.9762. Loss: 0.079\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:12<00:00,  7.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Test accuracy:0.6998. Loss:1.216\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Training accuracy: 0.9813. Loss: 0.062\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Test accuracy:0.6669. Loss:1.550\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Training accuracy: 0.9844. Loss: 0.049\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Test accuracy:0.7298. Loss:1.604\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Training accuracy: 0.9873. Loss: 0.041\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Test accuracy:0.7168. Loss:1.329\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Training accuracy: 0.9901. Loss: 0.032\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Test accuracy:0.7119. Loss:1.567\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Training accuracy: 0.9929. Loss: 0.025\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Test accuracy:0.6956. Loss:1.637\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Training accuracy: 0.9942. Loss: 0.019\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Test accuracy:0.7122. Loss:1.615\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Training accuracy: 0.9945. Loss: 0.018\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Test accuracy:0.7216. Loss:1.725\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Training accuracy: 0.9964. Loss: 0.011\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Test accuracy:0.7360. Loss:1.576\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Training accuracy: 0.9971. Loss: 0.009\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Test accuracy:0.7304. Loss:1.607\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Training accuracy: 0.9957. Loss: 0.042\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Test accuracy:0.6855. Loss:1.525\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Training accuracy: 0.9977. Loss: 0.026\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Test accuracy:0.7164. Loss:1.511\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Training accuracy: 0.9987. Loss: 0.015\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Test accuracy:0.7308. Loss:1.519\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Training accuracy: 0.9990. Loss: 0.006\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  8.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Test accuracy:0.7145. Loss:1.696\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Training accuracy: 0.9985. Loss: 0.012\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Test accuracy:0.6789. Loss:1.893\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Training accuracy: 0.9988. Loss: 0.013\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Test accuracy:0.6767. Loss:1.939\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Training accuracy: 0.9993. Loss: 0.007\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:09<00:00,  9.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Test accuracy:0.6757. Loss:2.142\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Training accuracy: 0.9998. Loss: 0.003\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Test accuracy:0.6868. Loss:1.961\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Training accuracy: 1.0000. Loss: 0.001\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Test accuracy:0.6946. Loss:2.058\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Training accuracy: 1.0000. Loss: 0.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 96/96 [00:10<00:00,  9.40it/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Test accuracy:0.7008. Loss:2.110\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}