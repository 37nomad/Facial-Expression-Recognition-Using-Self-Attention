{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654},{"sourceId":9517573,"sourceType":"datasetVersion","datasetId":5794401}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport numpy as np ","metadata":{"id":"579e9c4f-bb81-401a-9280-d215be513669","execution":{"iopub.status.busy":"2024-09-30T15:42:47.283795Z","iopub.execute_input":"2024-09-30T15:42:47.284170Z","iopub.status.idle":"2024-09-30T15:42:52.343819Z","shell.execute_reply.started":"2024-09-30T15:42:47.284125Z","shell.execute_reply":"2024-09-30T15:42:52.342860Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"Z9MA2G-FhPI_","execution":{"iopub.status.busy":"2024-09-30T15:42:56.340114Z","iopub.execute_input":"2024-09-30T15:42:56.340631Z","iopub.status.idle":"2024-09-30T15:42:56.345017Z","shell.execute_reply.started":"2024-09-30T15:42:56.340594Z","shell.execute_reply":"2024-09-30T15:42:56.344024Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    # 'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    # 'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    # 'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    # 'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}","metadata":{"id":"18e6d001-c057-4580-a5ff-d1f20c1b1f1b","execution":{"iopub.status.busy":"2024-09-30T15:42:58.607481Z","iopub.execute_input":"2024-09-30T15:42:58.608234Z","iopub.status.idle":"2024-09-30T15:42:58.612426Z","shell.execute_reply.started":"2024-09-30T15:42:58.608194Z","shell.execute_reply":"2024-09-30T15:42:58.611459Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)","metadata":{"id":"489ff69f-8164-49fa-b930-ca293d6bf96a","execution":{"iopub.status.busy":"2024-09-30T15:43:00.523170Z","iopub.execute_input":"2024-09-30T15:43:00.523548Z","iopub.status.idle":"2024-09-30T15:43:00.528859Z","shell.execute_reply.started":"2024-09-30T15:43:00.523511Z","shell.execute_reply":"2024-09-30T15:43:00.527877Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)","metadata":{"id":"ddcf8890-3b5f-4cf2-9556-2396fc691ed9","execution":{"iopub.status.busy":"2024-09-30T15:43:00.929087Z","iopub.execute_input":"2024-09-30T15:43:00.929780Z","iopub.status.idle":"2024-09-30T15:43:00.936818Z","shell.execute_reply.started":"2024-09-30T15:43:00.929721Z","shell.execute_reply":"2024-09-30T15:43:00.935808Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)","metadata":{"id":"0260a2df-76c8-413f-a7bf-a1c3b6b97c1f","execution":{"iopub.status.busy":"2024-09-30T15:43:01.362668Z","iopub.execute_input":"2024-09-30T15:43:01.363373Z","iopub.status.idle":"2024-09-30T15:43:01.369666Z","shell.execute_reply.started":"2024-09-30T15:43:01.363338Z","shell.execute_reply":"2024-09-30T15:43:01.368687Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.ca = ChannelAttention(planes)\n        self.sa = SpatialAttention()\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out = self.ca(out) * out\n        out = self.sa(out) * out\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out","metadata":{"id":"41fecb88-333e-4ba1-86e9-a86fd507c273","execution":{"iopub.status.busy":"2024-09-30T15:43:02.062833Z","iopub.execute_input":"2024-09-30T15:43:02.063237Z","iopub.status.idle":"2024-09-30T15:43:02.072397Z","shell.execute_reply.started":"2024-09-30T15:43:02.063200Z","shell.execute_reply":"2024-09-30T15:43:02.071458Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_heads, num_classes=7):\n        self.inplanes = 64\n        # self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n        self.attention = nn.MultiheadAttention(256, num_heads)\n        self.layer_norm = nn.LayerNorm(256)\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.classifier = nn.Sequential(\n            nn.Linear(256,128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, num_classes)\n        )\n\n        for m in self.classifier.modules():\n            if isinstance(m, nn.Linear):\n                fan_out = m.weight.size(0)  # fan-out\n                fan_in = m.weight.size(1) if m.weight.dim() > 1 else 0  # fan-in\n                init_range = 1.0 / math.sqrt(fan_in + fan_out)\n                m.weight.data.uniform_(-init_range, init_range)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        # x = self.layer4(x)\n\n        # x = self.avgpool(x)\n        # x = x.view(x.size(0), -1)\n        # x = self.fc(x)\n        batch_size, channels, height, width = x.shape\n        x = x.view(batch_size, channels, height*width).permute(0,2,1)\n\n        query = x\n        key = x\n        value = x\n\n        attn_output, _ = self.attention(query, key, value)\n        x = self.layer_norm(attn_output + x)\n        x = x.permute(0,2,1).view(batch_size, channels, height, width)\n        # x = nn.functional.adaptive_avg_pool2d(x,1).view(batch_size, -1)\n        x = self.global_avg_pool(x).view(batch_size, -1)\n\n        logits = self.classifier(x)\n\n        return logits","metadata":{"id":"42b16778-f805-4570-8455-179026a3c972","execution":{"iopub.status.busy":"2024-09-30T15:43:04.692293Z","iopub.execute_input":"2024-09-30T15:43:04.692644Z","iopub.status.idle":"2024-09-30T15:43:04.710557Z","shell.execute_reply.started":"2024-09-30T15:43:04.692610Z","shell.execute_reply":"2024-09-30T15:43:04.709619Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])","metadata":{"id":"03cd3076-fd58-4de5-a993-fac853812bce","execution":{"iopub.status.busy":"2024-09-30T15:43:12.050302Z","iopub.execute_input":"2024-09-30T15:43:12.050935Z","iopub.status.idle":"2024-09-30T15:43:12.055650Z","shell.execute_reply.started":"2024-09-30T15:43:12.050894Z","shell.execute_reply":"2024-09-30T15:43:12.054563Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Class Labels are 0-Indexed CAREFULL","metadata":{"id":"a2eb0ecd-292c-41ab-b5ee-d250558f39d9"}},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n\n        # Read the CSV file\n        self.data_frame = pd.read_csv(csv_file)\n\n        # Ensure the CSV file has columns 'filename' and 'class'\n        assert 'image' in self.data_frame.columns\n        assert 'label' in self.data_frame.columns\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        # Get the filename and class label\n        img_name = self.data_frame.iloc[idx, 0]  # Get the filename from the CSV\n        class_label = self.data_frame.iloc[idx, 1] - 1  # Get the class label from the CSV\n\n        # Construct the path to the image based on its class label\n        class_folder = os.path.join(self.image_dir, str(class_label+1))  # Convert class label to string\n        img_path = os.path.join(class_folder, img_name)\n\n        # Load the image\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n\n        return image, class_label","metadata":{"id":"b7badb95-b47f-42ab-85dc-d1e02aa63d0b","execution":{"iopub.status.busy":"2024-09-30T15:43:15.538320Z","iopub.execute_input":"2024-09-30T15:43:15.539036Z","iopub.status.idle":"2024-09-30T15:43:15.547896Z","shell.execute_reply.started":"2024-09-30T15:43:15.538996Z","shell.execute_reply":"2024-09-30T15:43:15.546934Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"image_directory = r\"/kaggle/input/raf-db-dataset/DATASET/train\"  # Directory containing class subfolders\ncsv_file_path = r\"/kaggle/input/raf-db-dataset/train_labels.csv\"","metadata":{"id":"aa27ec16-927e-4e09-b749-8a6d18011972","execution":{"iopub.status.busy":"2024-09-30T15:43:25.403817Z","iopub.execute_input":"2024-09-30T15:43:25.404463Z","iopub.status.idle":"2024-09-30T15:43:25.408714Z","shell.execute_reply.started":"2024-09-30T15:43:25.404424Z","shell.execute_reply":"2024-09-30T15:43:25.407789Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)\n","metadata":{"id":"a4ebf758-cb70-4921-aac6-3fc093533fc4","execution":{"iopub.status.busy":"2024-09-30T15:43:27.565360Z","iopub.execute_input":"2024-09-30T15:43:27.565984Z","iopub.status.idle":"2024-09-30T15:43:27.605645Z","shell.execute_reply.started":"2024-09-30T15:43:27.565947Z","shell.execute_reply":"2024-09-30T15:43:27.604724Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, num_workers=4, pin_memory=True, shuffle=True)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"27b73a65-5dc3-4bc4-a176-c39027548b2c","outputId":"a0ef7397-f0b3-4bac-d20a-5a0e8165b189","execution":{"iopub.status.busy":"2024-09-30T15:53:29.586520Z","iopub.execute_input":"2024-09-30T15:53:29.587303Z","iopub.status.idle":"2024-09-30T15:53:29.592286Z","shell.execute_reply.started":"2024-09-30T15:53:29.587261Z","shell.execute_reply":"2024-09-30T15:53:29.591191Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"f74qGWRn4mYD","execution":{"iopub.status.busy":"2024-09-30T15:53:41.557135Z","iopub.execute_input":"2024-09-30T15:53:41.558068Z","iopub.status.idle":"2024-09-30T15:53:41.578528Z","shell.execute_reply.started":"2024-09-30T15:53:41.558024Z","shell.execute_reply":"2024-09-30T15:53:41.577528Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41df7ed7-9c5a-4b01-b3cc-29ba888b181b","outputId":"917b2b2f-047a-4b25-fd4b-a170b42d28da","execution":{"iopub.status.busy":"2024-09-30T15:53:42.278231Z","iopub.execute_input":"2024-09-30T15:53:42.279087Z","iopub.status.idle":"2024-09-30T15:53:42.285130Z","shell.execute_reply.started":"2024-09-30T15:53:42.279047Z","shell.execute_reply":"2024-09-30T15:53:42.284208Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def resnet18_cbam(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    num_heads = 4\n    model = ResNet(BasicBlock, [2, 2, 2, 2], num_heads)\n    # if pretrained:\n    #     pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n    #     now_state_dict        = model.state_dict()\n    #     now_state_dict.update(pretrained_state_dict)\n    #     model.load_state_dict(now_state_dict, strict=False)\n    \n    # New Code Starts From Here\n    if pretrained:\n        checkpoint = torch.load(r\"/kaggle/input/epoch-4-weights/epoch_4_loss_0.4130449585500173.pth\")\n        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n    # Ends Here\n\n    \n    return model","metadata":{"id":"759108d4-98b8-4108-a954-c419f490ff54","execution":{"iopub.status.busy":"2024-09-30T15:53:42.969034Z","iopub.execute_input":"2024-09-30T15:53:42.969316Z","iopub.status.idle":"2024-09-30T15:53:42.975210Z","shell.execute_reply.started":"2024-09-30T15:53:42.969286Z","shell.execute_reply":"2024-09-30T15:53:42.974308Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = resnet18_cbam()\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"884eceee-4aae-4cbc-b395-33e82f9347c8","outputId":"e5495791-dd09-4a08-d8ea-282a4433d029","scrolled":true,"execution":{"iopub.status.busy":"2024-09-30T15:53:43.597028Z","iopub.execute_input":"2024-09-30T15:53:43.597350Z","iopub.status.idle":"2024-09-30T15:53:43.736227Z","shell.execute_reply.started":"2024-09-30T15:53:43.597316Z","shell.execute_reply":"2024-09-30T15:53:43.735322Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/4255134702.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(r\"/kaggle/input/epoch-4-weights/epoch_4_loss_0.4130449585500173.pth\")\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n  )\n  (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Linear(in_features=256, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=128, out_features=7, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)","metadata":{"id":"e6c77aa4-7e13-483f-938a-64df57fea96f","execution":{"iopub.status.busy":"2024-09-30T15:53:48.776798Z","iopub.execute_input":"2024-09-30T15:53:48.777422Z","iopub.status.idle":"2024-09-30T15:53:48.783229Z","shell.execute_reply.started":"2024-09-30T15:53:48.777383Z","shell.execute_reply":"2024-09-30T15:53:48.782179Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"os.makedirs('models', exist_ok=True)","metadata":{"id":"6BiC9Ry0nqd-","execution":{"iopub.status.busy":"2024-09-30T15:53:49.986086Z","iopub.execute_input":"2024-09-30T15:53:49.986830Z","iopub.status.idle":"2024-09-30T15:53:49.991249Z","shell.execute_reply.started":"2024-09-30T15:53:49.986791Z","shell.execute_reply":"2024-09-30T15:53:49.990107Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"id":"TOE5GMazqsMl","outputId":"c30bc8a6-b2f4-42ae-9b4c-73bda762e30a","execution":{"iopub.status.busy":"2024-09-30T15:53:51.858344Z","iopub.execute_input":"2024-09-30T15:53:51.859236Z","iopub.status.idle":"2024-09-30T15:53:51.865122Z","shell.execute_reply.started":"2024-09-30T15:53:51.859196Z","shell.execute_reply":"2024-09-30T15:53:51.864110Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, device, num_epochs=20):\n    # train_loader = pl.MpDeviceLoader(train_loader, device)\n    model.train()\n    # os.makedirs('models', exist_ok=True)\n    for epoch in range(num_epochs+1):\n        running_loss = 0.0\n\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs=model(images)\n            loss = criterion(outputs,labels)\n\n            loss.backward()\n            optimizer.step()\n            # xm.optimizer_step(optimizer)\n\n            running_loss += loss.item()\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n        if epoch > 10 :\n          torch.save({'iter': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),},\n                    os.path.join('models', \"tot20epoch_4heads_epoch_\"+str(epoch)+\"_loss_\"+str(epoch_loss)+\".pth\"))\n          print('Model saved.')","metadata":{"id":"29a08383-0aa7-4122-86ae-3bcf8da03420","execution":{"iopub.status.busy":"2024-09-30T15:53:55.951142Z","iopub.execute_input":"2024-09-30T15:53:55.951791Z","iopub.status.idle":"2024-09-30T15:53:55.960168Z","shell.execute_reply.started":"2024-09-30T15:53:55.951737Z","shell.execute_reply":"2024-09-30T15:53:55.959163Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train(model, train_loader, criterion, optimizer, device, num_epochs=20)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58970af0-2447-4401-aeee-de55d874ca94","outputId":"b138da59-58d3-410c-a550-7dfb98216bd1","execution":{"iopub.status.busy":"2024-09-30T15:53:57.540056Z","iopub.execute_input":"2024-09-30T15:53:57.540689Z","iopub.status.idle":"2024-09-30T16:07:39.168693Z","shell.execute_reply.started":"2024-09-30T15:53:57.540647Z","shell.execute_reply":"2024-09-30T16:07:39.167612Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 384/384 [00:38<00:00,  9.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20], Loss: 0.4395\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/20], Loss: 0.3002\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:38<00:00,  9.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/20], Loss: 0.2522\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/20], Loss: 0.1997\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/20], Loss: 0.1732\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/20], Loss: 0.1484\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/20], Loss: 0.1372\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/20], Loss: 0.1144\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/20], Loss: 0.1085\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/20], Loss: 0.0985\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/20], Loss: 0.0936\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/20], Loss: 0.0882\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/20], Loss: 0.0768\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/20], Loss: 0.0722\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/20], Loss: 0.0764\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/20], Loss: 0.0729\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/20], Loss: 0.0738\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/20], Loss: 0.0574\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [19/20], Loss: 0.0691\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [20/20], Loss: 0.0650\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:39<00:00,  9.83it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [21/20], Loss: 0.0515\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_image_directory = r\"/kaggle/input/raf-db-dataset/DATASET/test\"\ntest_csv_file_path = r\"/kaggle/input/raf-db-dataset/test_labels.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-09-30T16:09:28.053453Z","iopub.execute_input":"2024-09-30T16:09:28.054265Z","iopub.status.idle":"2024-09-30T16:09:28.058778Z","shell.execute_reply.started":"2024-09-30T16:09:28.054221Z","shell.execute_reply":"2024-09-30T16:09:28.057876Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomImageDataset(test_image_directory, test_csv_file_path, transform)","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:04:09.027984Z","iopub.status.busy":"2024-09-29T18:04:09.027584Z","iopub.status.idle":"2024-09-29T18:04:09.040373Z","shell.execute_reply":"2024-09-29T18:04:09.039653Z","shell.execute_reply.started":"2024-09-29T18:04:09.027947Z"},"id":"a78d1b81-84f7-41f7-9f55-ed6cef4a300c"},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:05:04.979805Z","iopub.status.busy":"2024-09-29T18:05:04.979061Z","iopub.status.idle":"2024-09-29T18:05:04.984185Z","shell.execute_reply":"2024-09-29T18:05:04.983212Z","shell.execute_reply.started":"2024-09-29T18:05:04.979766Z"},"id":"dcf42031-0336-4cdc-a490-8ace98c5dd2a"},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load(r\"/kaggle/working/models/epoch_4_loss_0.4130449585500173.pth\")","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:11:46.875084Z","iopub.status.busy":"2024-09-29T18:11:46.874472Z","iopub.status.idle":"2024-09-29T18:11:46.941625Z","shell.execute_reply":"2024-09-29T18:11:46.940712Z","shell.execute_reply.started":"2024-09-29T18:11:46.875043Z"},"scrolled":true},"execution_count":40,"outputs":[{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_30/2788366729.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n\n  checkpoint = torch.load(r\"/kaggle/working/models/epoch_4_loss_0.4130449585500173.pth\")\n"}]},{"cell_type":"code","source":"model.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:13:50.010670Z","iopub.status.busy":"2024-09-29T18:13:50.010304Z","iopub.status.idle":"2024-09-29T18:13:50.025949Z","shell.execute_reply":"2024-09-29T18:13:50.025123Z","shell.execute_reply.started":"2024-09-29T18:13:50.010635Z"},"id":"20b57c11-c158-48b1-b0e7-e400f2908577","scrolled":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (ca): ChannelAttention(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (max_pool): AdaptiveMaxPool2d(output_size=1)\n","        (fc): Sequential(\n","          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): ReLU()\n","          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (sigmoid): Sigmoid()\n","      )\n","      (sa): SpatialAttention(\n","        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (ca): ChannelAttention(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (max_pool): AdaptiveMaxPool2d(output_size=1)\n","        (fc): Sequential(\n","          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): ReLU()\n","          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (sigmoid): Sigmoid()\n","      )\n","      (sa): SpatialAttention(\n","        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (ca): ChannelAttention(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (max_pool): AdaptiveMaxPool2d(output_size=1)\n","        (fc): Sequential(\n","          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): ReLU()\n","          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (sigmoid): Sigmoid()\n","      )\n","      (sa): SpatialAttention(\n","        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (ca): ChannelAttention(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (max_pool): AdaptiveMaxPool2d(output_size=1)\n","        (fc): Sequential(\n","          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): ReLU()\n","          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (sigmoid): Sigmoid()\n","      )\n","      (sa): SpatialAttention(\n","        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (ca): ChannelAttention(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (max_pool): AdaptiveMaxPool2d(output_size=1)\n","        (fc): Sequential(\n","          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): ReLU()\n","          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (sigmoid): Sigmoid()\n","      )\n","      (sa): SpatialAttention(\n","        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","        (sigmoid): Sigmoid()\n","      )\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (ca): ChannelAttention(\n","        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","        (max_pool): AdaptiveMaxPool2d(output_size=1)\n","        (fc): Sequential(\n","          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): ReLU()\n","          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        )\n","        (sigmoid): Sigmoid()\n","      )\n","      (sa): SpatialAttention(\n","        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n","        (sigmoid): Sigmoid()\n","      )\n","    )\n","  )\n","  (attention): MultiheadAttention(\n","    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n","  )\n","  (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","  (classifier): Linear(in_features=256, out_features=7, bias=True)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"all_preds=[]\nall_labels=[]\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs,1)\n#         predicted+=1\n        \n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nall_preds = np.array(all_preds)\nall_labels = np.array(all_labels)","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:28:42.513837Z","iopub.status.busy":"2024-09-29T18:28:42.513183Z","iopub.status.idle":"2024-09-29T18:28:54.332048Z","shell.execute_reply":"2024-09-29T18:28:54.331086Z","shell.execute_reply.started":"2024-09-29T18:28:42.513797Z"},"id":"3f08e78f-164c-44f4-ab33-76d3355754af"},"execution_count":51,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 96/96 [00:11<00:00,  8.13it/s]\n"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(all_labels, all_preds)\naccuracy","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:29:02.323684Z","iopub.status.busy":"2024-09-29T18:29:02.322897Z","iopub.status.idle":"2024-09-29T18:29:02.331666Z","shell.execute_reply":"2024-09-29T18:29:02.330574Z","shell.execute_reply.started":"2024-09-29T18:29:02.323645Z"}},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":["0.7535853976531942"]},"metadata":{}}]},{"cell_type":"code","source":"all_preds.min()","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:30:06.766214Z","iopub.status.busy":"2024-09-29T18:30:06.765811Z","iopub.status.idle":"2024-09-29T18:30:06.772208Z","shell.execute_reply":"2024-09-29T18:30:06.771238Z","shell.execute_reply.started":"2024-09-29T18:30:06.766175Z"}},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{}}]},{"cell_type":"code","source":"all_labels.min()","metadata":{"execution":{"iopub.execute_input":"2024-09-29T18:30:11.700927Z","iopub.status.busy":"2024-09-29T18:30:11.700524Z","iopub.status.idle":"2024-09-29T18:30:11.707431Z","shell.execute_reply":"2024-09-29T18:30:11.706346Z","shell.execute_reply.started":"2024-09-29T18:30:11.700881Z"}},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}