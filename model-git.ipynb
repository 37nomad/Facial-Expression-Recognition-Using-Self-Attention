{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom tqdm import tqdm","metadata":{"id":"579e9c4f-bb81-401a-9280-d215be513669","execution":{"iopub.status.busy":"2024-09-29T17:27:39.397795Z","iopub.execute_input":"2024-09-29T17:27:39.398120Z","iopub.status.idle":"2024-09-29T17:27:44.395336Z","shell.execute_reply.started":"2024-09-29T17:27:39.398086Z","shell.execute_reply":"2024-09-29T17:27:44.394271Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"Z9MA2G-FhPI_","execution":{"iopub.status.busy":"2024-09-29T17:27:48.466286Z","iopub.execute_input":"2024-09-29T17:27:48.466781Z","iopub.status.idle":"2024-09-29T17:27:48.470561Z","shell.execute_reply.started":"2024-09-29T17:27:48.466744Z","shell.execute_reply":"2024-09-29T17:27:48.469685Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    # 'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    # 'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    # 'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    # 'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}","metadata":{"id":"18e6d001-c057-4580-a5ff-d1f20c1b1f1b","execution":{"iopub.status.busy":"2024-09-29T17:27:49.295190Z","iopub.execute_input":"2024-09-29T17:27:49.295505Z","iopub.status.idle":"2024-09-29T17:27:49.300202Z","shell.execute_reply.started":"2024-09-29T17:27:49.295474Z","shell.execute_reply":"2024-09-29T17:27:49.299091Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)","metadata":{"id":"489ff69f-8164-49fa-b930-ca293d6bf96a","execution":{"iopub.status.busy":"2024-09-29T17:27:49.978715Z","iopub.execute_input":"2024-09-29T17:27:49.979390Z","iopub.status.idle":"2024-09-29T17:27:49.984149Z","shell.execute_reply.started":"2024-09-29T17:27:49.979342Z","shell.execute_reply":"2024-09-29T17:27:49.983193Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)","metadata":{"id":"ddcf8890-3b5f-4cf2-9556-2396fc691ed9","execution":{"iopub.status.busy":"2024-09-29T17:27:50.492080Z","iopub.execute_input":"2024-09-29T17:27:50.492787Z","iopub.status.idle":"2024-09-29T17:27:50.499740Z","shell.execute_reply.started":"2024-09-29T17:27:50.492753Z","shell.execute_reply":"2024-09-29T17:27:50.498718Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)","metadata":{"id":"0260a2df-76c8-413f-a7bf-a1c3b6b97c1f","execution":{"iopub.status.busy":"2024-09-29T17:27:50.948920Z","iopub.execute_input":"2024-09-29T17:27:50.949218Z","iopub.status.idle":"2024-09-29T17:27:50.955852Z","shell.execute_reply.started":"2024-09-29T17:27:50.949186Z","shell.execute_reply":"2024-09-29T17:27:50.954909Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.ca = ChannelAttention(planes)\n        self.sa = SpatialAttention()\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        out = self.ca(out) * out\n        out = self.sa(out) * out\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out","metadata":{"id":"41fecb88-333e-4ba1-86e9-a86fd507c273","execution":{"iopub.status.busy":"2024-09-29T17:27:51.488608Z","iopub.execute_input":"2024-09-29T17:27:51.488917Z","iopub.status.idle":"2024-09-29T17:27:51.498119Z","shell.execute_reply.started":"2024-09-29T17:27:51.488886Z","shell.execute_reply":"2024-09-29T17:27:51.497266Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_heads, num_classes=7):\n        self.inplanes = 64\n        # self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        # self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n        self.attention = nn.MultiheadAttention(256, num_heads)\n        self.layer_norm = nn.LayerNorm(256)\n        self.classifier = nn.Linear(256, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        # x = self.layer4(x)\n\n        # x = self.avgpool(x)\n        # x = x.view(x.size(0), -1)\n        # x = self.fc(x)\n        batch_size, channels, height, width = x.shape\n        x = x.view(batch_size, channels, height*width).permute(0,2,1)\n\n        query = x\n        key = x\n        value = x\n\n        attn_output, _ = self.attention(query, key, value)\n        x = self.layer_norm(attn_output + x)\n        x = x.permute(0,2,1).view(batch_size, channels, height, width)\n        x = nn.functional.adaptive_avg_pool2d(x,1).view(batch_size, -1)\n\n        logits = self.classifier(x)\n\n        return logits","metadata":{"id":"42b16778-f805-4570-8455-179026a3c972","execution":{"iopub.status.busy":"2024-09-29T17:27:52.006771Z","iopub.execute_input":"2024-09-29T17:27:52.007080Z","iopub.status.idle":"2024-09-29T17:27:52.023944Z","shell.execute_reply.started":"2024-09-29T17:27:52.007048Z","shell.execute_reply":"2024-09-29T17:27:52.023001Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])","metadata":{"id":"03cd3076-fd58-4de5-a993-fac853812bce","execution":{"iopub.status.busy":"2024-09-29T17:27:52.422376Z","iopub.execute_input":"2024-09-29T17:27:52.422975Z","iopub.status.idle":"2024-09-29T17:27:52.427426Z","shell.execute_reply.started":"2024-09-29T17:27:52.422935Z","shell.execute_reply":"2024-09-29T17:27:52.426524Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Class Labels are 0-Indexed CAREFULL","metadata":{"id":"a2eb0ecd-292c-41ab-b5ee-d250558f39d9"}},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n\n        # Read the CSV file\n        self.data_frame = pd.read_csv(csv_file)\n\n        # Ensure the CSV file has columns 'filename' and 'class'\n        assert 'image' in self.data_frame.columns\n        assert 'label' in self.data_frame.columns\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        # Get the filename and class label\n        img_name = self.data_frame.iloc[idx, 0]  # Get the filename from the CSV\n        class_label = self.data_frame.iloc[idx, 1] - 1  # Get the class label from the CSV\n\n        # Construct the path to the image based on its class label\n        class_folder = os.path.join(self.image_dir, str(class_label+1))  # Convert class label to string\n        img_path = os.path.join(class_folder, img_name)\n\n        # Load the image\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n\n        return image, class_label","metadata":{"id":"b7badb95-b47f-42ab-85dc-d1e02aa63d0b","execution":{"iopub.status.busy":"2024-09-29T17:27:54.247599Z","iopub.execute_input":"2024-09-29T17:27:54.247983Z","iopub.status.idle":"2024-09-29T17:27:54.256248Z","shell.execute_reply.started":"2024-09-29T17:27:54.247946Z","shell.execute_reply":"2024-09-29T17:27:54.255367Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"image_directory = r\"/kaggle/input/raf-db-dataset/DATASET/train\"  # Directory containing class subfolders\ncsv_file_path = r\"/kaggle/input/raf-db-dataset/train_labels.csv\"","metadata":{"id":"aa27ec16-927e-4e09-b749-8a6d18011972","execution":{"iopub.status.busy":"2024-09-29T17:29:47.154819Z","iopub.execute_input":"2024-09-29T17:29:47.155479Z","iopub.status.idle":"2024-09-29T17:29:47.159692Z","shell.execute_reply.started":"2024-09-29T17:29:47.155441Z","shell.execute_reply":"2024-09-29T17:29:47.158705Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)\n","metadata":{"id":"a4ebf758-cb70-4921-aac6-3fc093533fc4","execution":{"iopub.status.busy":"2024-09-29T17:29:48.804802Z","iopub.execute_input":"2024-09-29T17:29:48.805589Z","iopub.status.idle":"2024-09-29T17:29:48.838901Z","shell.execute_reply.started":"2024-09-29T17:29:48.805550Z","shell.execute_reply":"2024-09-29T17:29:48.838173Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, num_workers=8, pin_memory=True, shuffle=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27b73a65-5dc3-4bc4-a176-c39027548b2c","outputId":"a0ef7397-f0b3-4bac-d20a-5a0e8165b189","execution":{"iopub.status.busy":"2024-09-29T17:29:52.616424Z","iopub.execute_input":"2024-09-29T17:29:52.617153Z","iopub.status.idle":"2024-09-29T17:29:52.624344Z","shell.execute_reply.started":"2024-09-29T17:29:52.617116Z","shell.execute_reply":"2024-09-29T17:29:52.623399Z"},"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"f74qGWRn4mYD","execution":{"iopub.status.busy":"2024-09-29T17:30:29.641086Z","iopub.execute_input":"2024-09-29T17:30:29.641796Z","iopub.status.idle":"2024-09-29T17:30:29.645922Z","shell.execute_reply.started":"2024-09-29T17:30:29.641759Z","shell.execute_reply":"2024-09-29T17:30:29.644911Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41df7ed7-9c5a-4b01-b3cc-29ba888b181b","outputId":"917b2b2f-047a-4b25-fd4b-a170b42d28da","execution":{"iopub.status.busy":"2024-09-29T17:30:30.340094Z","iopub.execute_input":"2024-09-29T17:30:30.340852Z","iopub.status.idle":"2024-09-29T17:30:30.399186Z","shell.execute_reply.started":"2024-09-29T17:30:30.340818Z","shell.execute_reply":"2024-09-29T17:30:30.398336Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def resnet18_cbam(pretrained=True, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    num_heads = 2\n    model = ResNet(BasicBlock, [2, 2, 2, 2], num_heads)\n    if pretrained:\n        pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n        now_state_dict        = model.state_dict()\n        now_state_dict.update(pretrained_state_dict)\n        model.load_state_dict(now_state_dict, strict=False)\n    return model","metadata":{"id":"759108d4-98b8-4108-a954-c419f490ff54","execution":{"iopub.status.busy":"2024-09-29T17:30:34.610611Z","iopub.execute_input":"2024-09-29T17:30:34.611030Z","iopub.status.idle":"2024-09-29T17:30:34.617907Z","shell.execute_reply.started":"2024-09-29T17:30:34.610978Z","shell.execute_reply":"2024-09-29T17:30:34.616607Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = resnet18_cbam()\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"884eceee-4aae-4cbc-b395-33e82f9347c8","outputId":"e5495791-dd09-4a08-d8ea-282a4433d029","execution":{"iopub.status.busy":"2024-09-29T17:32:50.987854Z","iopub.execute_input":"2024-09-29T17:32:50.988248Z","iopub.status.idle":"2024-09-29T17:32:51.175622Z","shell.execute_reply.started":"2024-09-29T17:32:50.988211Z","shell.execute_reply":"2024-09-29T17:32:51.174552Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ca): ChannelAttention(\n        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n        (max_pool): AdaptiveMaxPool2d(output_size=1)\n        (fc): Sequential(\n          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): ReLU()\n          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n        (sigmoid): Sigmoid()\n      )\n      (sa): SpatialAttention(\n        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n        (sigmoid): Sigmoid()\n      )\n    )\n  )\n  (attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n  )\n  (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (classifier): Linear(in_features=256, out_features=7, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)","metadata":{"id":"e6c77aa4-7e13-483f-938a-64df57fea96f","execution":{"iopub.status.busy":"2024-09-29T17:32:53.661464Z","iopub.execute_input":"2024-09-29T17:32:53.662216Z","iopub.status.idle":"2024-09-29T17:32:53.667513Z","shell.execute_reply.started":"2024-09-29T17:32:53.662175Z","shell.execute_reply":"2024-09-29T17:32:53.666573Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"os.makedirs('models', exist_ok=True)","metadata":{"id":"6BiC9Ry0nqd-","execution":{"iopub.status.busy":"2024-09-29T17:32:55.394286Z","iopub.execute_input":"2024-09-29T17:32:55.394661Z","iopub.status.idle":"2024-09-29T17:32:55.399344Z","shell.execute_reply.started":"2024-09-29T17:32:55.394623Z","shell.execute_reply":"2024-09-29T17:32:55.398395Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"id":"TOE5GMazqsMl","outputId":"c30bc8a6-b2f4-42ae-9b4c-73bda762e30a","colab":{"base_uri":"https://localhost:8080/","height":55},"execution":{"iopub.status.busy":"2024-09-29T17:32:57.081907Z","iopub.execute_input":"2024-09-29T17:32:57.082252Z","iopub.status.idle":"2024-09-29T17:32:57.088047Z","shell.execute_reply.started":"2024-09-29T17:32:57.082216Z","shell.execute_reply":"2024-09-29T17:32:57.087077Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, device, num_epochs=5):\n    # train_loader = pl.MpDeviceLoader(train_loader, device)\n    model.train()\n    # os.makedirs('models', exist_ok=True)\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs=model(images)\n            loss = criterion(outputs,labels)\n\n            loss.backward()\n            optimizer.step()\n            # xm.optimizer_step(optimizer)\n\n            running_loss += loss.item()\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n        if epoch > 2 :\n          torch.save({'iter': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),},\n                    os.path.join('models', \"epoch_\"+str(epoch)+\"_loss_\"+str(epoch_loss)+\".pth\"))\n          print('Model saved.')","metadata":{"id":"29a08383-0aa7-4122-86ae-3bcf8da03420","execution":{"iopub.status.busy":"2024-09-29T17:33:14.387710Z","iopub.execute_input":"2024-09-29T17:33:14.388574Z","iopub.status.idle":"2024-09-29T17:33:14.396462Z","shell.execute_reply.started":"2024-09-29T17:33:14.388533Z","shell.execute_reply":"2024-09-29T17:33:14.395601Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train(model, train_loader, criterion, optimizer, device, num_epochs=5)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58970af0-2447-4401-aeee-de55d874ca94","outputId":"b138da59-58d3-410c-a550-7dfb98216bd1","execution":{"iopub.status.busy":"2024-09-29T17:33:15.619726Z","iopub.execute_input":"2024-09-29T17:33:15.620138Z","iopub.status.idle":"2024-09-29T17:36:38.029803Z","shell.execute_reply.started":"2024-09-29T17:33:15.620098Z","shell.execute_reply":"2024-09-29T17:36:38.028760Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"100%|██████████| 384/384 [00:41<00:00,  9.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5], Loss: 1.2328\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/5], Loss: 0.8029\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/5], Loss: 0.6365\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/5], Loss: 0.5159\nModel saved.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [00:40<00:00,  9.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/5], Loss: 0.4130\nModel saved.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"94be1222-6c60-421e-a0f4-3670f83b3a68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"a78d1b81-84f7-41f7-9f55-ed6cef4a300c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"dcf42031-0336-4cdc-a490-8ace98c5dd2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"20b57c11-c158-48b1-b0e7-e400f2908577"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3f08e78f-164c-44f4-ab33-76d3355754af"},"execution_count":null,"outputs":[]}]}