{"metadata":{"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport torch.optim as optim\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nimport numpy as np \nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torchvision.transforms as T\nfrom pytorchcv.model_provider import get_model","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.744629Z","iopub.execute_input":"2024-10-03T21:35:19.745051Z","iopub.status.idle":"2024-10-03T21:35:19.753014Z","shell.execute_reply.started":"2024-10-03T21:35:19.744995Z","shell.execute_reply":"2024-10-03T21:35:19.751998Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# pip install pytorchcv","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.754756Z","iopub.execute_input":"2024-10-03T21:35:19.755407Z","iopub.status.idle":"2024-10-03T21:35:19.760336Z","shell.execute_reply.started":"2024-10-03T21:35:19.755362Z","shell.execute_reply":"2024-10-03T21:35:19.759437Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.762048Z","iopub.execute_input":"2024-10-03T21:35:19.762659Z","iopub.status.idle":"2024-10-03T21:35:19.767525Z","shell.execute_reply.started":"2024-10-03T21:35:19.762613Z","shell.execute_reply":"2024-10-03T21:35:19.766544Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class PatchExtraction(nn.Module):\n    def __init__(self):\n        super(PatchExtraction, self).__init__()\n        # First separable convolution (depthwise + pointwise)\n        self.depthwise_conv1 = nn.Conv2d(512, 512, kernel_size=4, stride=4, padding=1, groups=512)\n        self.pointwise_conv1 = nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0)\n        \n        # Second separable convolution (depthwise + pointwise)\n        self.depthwise_conv2 = nn.Conv2d(256, 256, kernel_size=2, stride=2, padding=0, groups=256)\n        self.pointwise_conv2 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n\n        # Normal Conv (used directly)\n        self.conv3 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n        # First separable convolution\n        x = F.relu(self.depthwise_conv1(x))\n        x = F.relu(self.pointwise_conv1(x))\n\n        # Second separable convolution\n        x = F.relu(self.depthwise_conv2(x))\n        x = F.relu(self.pointwise_conv2(x))\n\n        # Normal convolution\n        x = F.relu(self.conv3(x))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.768599Z","iopub.execute_input":"2024-10-03T21:35:19.768878Z","iopub.status.idle":"2024-10-03T21:35:19.779191Z","shell.execute_reply.started":"2024-10-03T21:35:19.768843Z","shell.execute_reply":"2024-10-03T21:35:19.778242Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, embed_size, num_heads=1):\n        super(SelfAttention, self).__init__()\n        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads)\n\n    def forward(self, x):\n        # Attention expects input of shape [sequence_length, batch_size, embed_dim]\n        x = x.unsqueeze(0)  # Adding sequence length as 1\n        attn_output, _ = self.attention(x, x, x)\n        return attn_output.squeeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.780945Z","iopub.execute_input":"2024-10-03T21:35:19.781303Z","iopub.status.idle":"2024-10-03T21:35:19.787570Z","shell.execute_reply.started":"2024-10-03T21:35:19.781256Z","shell.execute_reply":"2024-10-03T21:35:19.786733Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class PattLite(nn.Module):\n    def __init__(self):\n        super(PattLite, self).__init__()\n        \n        # Preprocessing: resizing and augmentation\n#         self.transform = transforms.Compose([\n#             transforms.Resize((224, 224)),\n#             transforms.ToTensor(),\n#         ])\n        \n        # Backbone (MobileNet with last 29 layers removed)\n        self.backbone = get_model('mobilenetv1', pretrained=True)\n        self.backbone = nn.Sequential(*list(self.backbone.features.children())[:-29])\n        for param in self.backbone.parameters():\n            param.requires_grad = False\n\n        # Patch extraction, attention, and global average pooling layers\n        self.patch_extraction = PatchExtraction()\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(0.1)\n\n        # Pre-classification layer\n        self.pre_classification = nn.Sequential(\n            nn.Linear(256, 32),\n            nn.ReLU(),\n            nn.BatchNorm1d(32)\n        )\n\n        # Self-attention\n        self.self_attention = SelfAttention(embed_size=32)\n\n        # Final classification layer\n        self.classifier = nn.Linear(32, 7)\n\n    def forward(self, x):\n        # Apply transformations\n#         x = self.transform(x)\n        \n        # Backbone (MobileNetV2)\n        x = self.backbone(x)\n        \n        # Patch extraction\n        x = self.patch_extraction(x)\n        \n        # Global average pooling\n        x = self.global_avg_pool(x)\n        x = x.view(x.size(0), -1)  # Flatten (N, 256)\n        \n        # Dropout before final classification\n        x = self.dropout(x)\n        \n        # Pre-classification layer\n        x = self.pre_classification(x)\n        \n        # Self-attention (expects [seq_len, batch_size, embed_dim])\n        x = self.self_attention(x.unsqueeze(0)).squeeze(0)  # Apply self-attention\n        \n        # Final classification layer\n        x = self.classifier(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.788617Z","iopub.execute_input":"2024-10-03T21:35:19.788906Z","iopub.status.idle":"2024-10-03T21:35:19.800054Z","shell.execute_reply.started":"2024-10-03T21:35:19.788877Z","shell.execute_reply":"2024-10-03T21:35:19.799198Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# pip install --upgrade torchvision","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-03T21:35:19.902193Z","iopub.execute_input":"2024-10-03T21:35:19.902639Z","iopub.status.idle":"2024-10-03T21:35:19.906856Z","shell.execute_reply.started":"2024-10-03T21:35:19.902603Z","shell.execute_reply":"2024-10-03T21:35:19.905878Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = PattLite()","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:19.908959Z","iopub.execute_input":"2024-10-03T21:35:19.909415Z","iopub.status.idle":"2024-10-03T21:35:20.060413Z","shell.execute_reply.started":"2024-10-03T21:35:19.909370Z","shell.execute_reply":"2024-10-03T21:35:20.058431Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPattLite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36mPattLite.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(PattLite, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Preprocessing: resizing and augmentation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#         self.transform = transforms.Compose([\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#             transforms.Resize((224, 224)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Backbone (MobileNet with last 29 layers removed)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilenetv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mchildren())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m29\u001b[39m])\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mparameters():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorchcv/model_provider.py:1380\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(name, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _models:\n\u001b[0;32m-> 1380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   1381\u001b[0m net \u001b[38;5;241m=\u001b[39m _models[name](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\n","\u001b[0;31mValueError\u001b[0m: Unsupported model: mobilenetv1"],"ename":"ValueError","evalue":"Unsupported model: mobilenetv1","output_type":"error"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nscheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, min_lr=1e-6)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.061227Z","iopub.status.idle":"2024-10-03T21:35:20.061602Z","shell.execute_reply.started":"2024-10-03T21:35:20.061424Z","shell.execute_reply":"2024-10-03T21:35:20.061442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.062769Z","iopub.status.idle":"2024-10-03T21:35:20.063198Z","shell.execute_reply.started":"2024-10-03T21:35:20.062959Z","shell.execute_reply":"2024-10-03T21:35:20.062994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.064679Z","iopub.status.idle":"2024-10-03T21:35:20.065032Z","shell.execute_reply.started":"2024-10-03T21:35:20.064858Z","shell.execute_reply":"2024-10-03T21:35:20.064876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_dir, csv_file, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n\n        # Read the CSV file\n        self.data_frame = pd.read_csv(csv_file)\n\n        # Ensure the CSV file has columns 'filename' and 'class'\n        assert 'image' in self.data_frame.columns\n        assert 'label' in self.data_frame.columns\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        # Get the filename and class label\n        img_name = self.data_frame.iloc[idx, 0]  # Get the filename from the CSV\n        class_label = self.data_frame.iloc[idx, 1] - 1  # Get the class label from the CSV\n\n        # Construct the path to the image based on its class label\n        class_folder = os.path.join(self.image_dir, str(class_label+1))  # Convert class label to string\n        img_path = os.path.join(class_folder, img_name)\n\n        # Load the image\n        image = Image.open(img_path).convert('RGB')\n\n        # Apply transformations\n        if self.transform:\n            image = self.transform(image)\n\n        return image, class_label","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.066463Z","iopub.status.idle":"2024-10-03T21:35:20.066814Z","shell.execute_reply.started":"2024-10-03T21:35:20.066641Z","shell.execute_reply":"2024-10-03T21:35:20.066659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_directory = r\"/kaggle/input/raf-db-dataset/DATASET/train\"  # Directory containing class subfolders\ncsv_file_path = r\"/kaggle/input/raf-db-dataset/train_labels.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.068425Z","iopub.status.idle":"2024-10-03T21:35:20.068901Z","shell.execute_reply.started":"2024-10-03T21:35:20.068646Z","shell.execute_reply":"2024-10-03T21:35:20.068671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomImageDataset(image_dir=image_directory, csv_file=csv_file_path, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.070482Z","iopub.status.idle":"2024-10-03T21:35:20.070941Z","shell.execute_reply.started":"2024-10-03T21:35:20.070699Z","shell.execute_reply":"2024-10-03T21:35:20.070723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, num_workers=4, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.071864Z","iopub.status.idle":"2024-10-03T21:35:20.072367Z","shell.execute_reply.started":"2024-10-03T21:35:20.072094Z","shell.execute_reply":"2024-10-03T21:35:20.072118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_directory = r\"/kaggle/input/raf-db-dataset/DATASET/test\"\ntest_csv_file_path = r\"/kaggle/input/raf-db-dataset/test_labels.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.073946Z","iopub.status.idle":"2024-10-03T21:35:20.074444Z","shell.execute_reply.started":"2024-10-03T21:35:20.074164Z","shell.execute_reply":"2024-10-03T21:35:20.074196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomImageDataset(test_image_directory, test_csv_file_path, transform)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.075849Z","iopub.status.idle":"2024-10-03T21:35:20.076202Z","shell.execute_reply.started":"2024-10-03T21:35:20.076026Z","shell.execute_reply":"2024-10-03T21:35:20.076044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=8, num_workers=4, pin_memory=True, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.077666Z","iopub.status.idle":"2024-10-03T21:35:20.078016Z","shell.execute_reply.started":"2024-10-03T21:35:20.077841Z","shell.execute_reply":"2024-10-03T21:35:20.077859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, test_loader, num_epochs):\n#     best_val_acc = 0\n#     early_stopping_counter = 0\n    best_acc = 0\n    for epoch in range(1, num_epochs+1):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # Training loop\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n        \n        # Calculate training accuracy\n        train_acc = 100. * correct / total\n        \n        # Validation loop\n        model.eval()\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in test_loader:\n                outputs = model(inputs)\n                _, predicted = outputs.max(1)\n                val_total += labels.size(0)\n                val_correct += predicted.eq(labels).sum().item()\n        \n        val_acc = 100. * val_correct / val_total\n        \n        print(f'Epoch {epoch}/{num_epochs}, Loss: {running_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n        \n        # Scheduler step\n        scheduler.step(val_acc)\n        \n        # Early stopping\n        if val_acc > best_acc:\n            best_acc = val_acc\n#             early_stopping_counter = 0\n            torch.save(model.state_dict(), f\"best_model_epoch{epoch}_acc{val_acc}.pth\")\n#         else:\n#             early_stopping_counter += 1\n#             if early_stopping_counter > patience:\n#                 print(\"Early stopping!\")\n#                 break\n","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.079837Z","iopub.status.idle":"2024-10-03T21:35:20.080327Z","shell.execute_reply.started":"2024-10-03T21:35:20.080055Z","shell.execute_reply":"2024-10-03T21:35:20.080081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_model(model, train_loader, test_loader, 20)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T21:35:20.081430Z","iopub.status.idle":"2024-10-03T21:35:20.081890Z","shell.execute_reply.started":"2024-10-03T21:35:20.081649Z","shell.execute_reply":"2024-10-03T21:35:20.081674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}